{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ·ï¸ Funzionamento dello Script (Passo dopo Passo)\n",
    "\n",
    "### 1) Caricamento e Pre-elaborazione dei Dati\n",
    "Si parte caricando il file CSV contenente le informazioni aziendali. Dopo aver letto il dataset, vengono selezionate le sole colonne considerate importanti per il matching, in questo caso:\n",
    "\n",
    "- `company_name`\n",
    "- `industry`\n",
    "- `headquarters_city`\n",
    "\n",
    "A questo punto, si eliminano (drop) le righe che non hanno il nome dellâ€™azienda (`company_name`), perchÃ© tale colonna Ã¨ ritenuta fondamentale per confrontare i record. Infine, si stampa quanti record validi rimangono dopo questa pulizia.\n",
    "\n",
    "**PerchÃ© si fa:** riduciamo il DataFrame a ciÃ² che serve per identificare la stessa entitÃ , eliminando dati mancanti sui campi essenziali.\n",
    "\n",
    "### 2) Creazione di un â€œBlockingâ€ non troppo restrittivo\n",
    "Lo script utilizza la libreria `recordlinkage` per definire le regole di blocco (blocking). In particolare, si creano due regole:\n",
    "\n",
    "- **Exact Block su `industry`:**\n",
    "    Raggruppa i record per settore, cosÃ¬ il confronto avviene solo tra aziende che appartengono allo stesso `industry`.\n",
    "\n",
    "- **SortedNeighbourhood su `company_name` con finestra = 5:**\n",
    "    Ordina le aziende in base al nome e poi confronta ogni azienda con le 5 precedenti e le 5 successive. Lo scopo Ã¨ catturare nomi che sono â€œviciniâ€ a livello alfabetico, evitando di confrontare aziende i cui nomi sarebbero nettamente diversi.\n",
    "\n",
    "Il risultato di queste due regole viene unito (logica OR). CiÃ² significa che una coppia di record passa alla fase successiva se soddisfa almeno una delle due condizioni di blocco.\n",
    "\n",
    "Alla fine, si stampa quante coppie candidate abbiamo ottenuto: Ã¨ il numero di possibili confronti che andranno analizzati piÃ¹ a fondo.\n",
    "\n",
    "**PerchÃ© si fa:** il blocking Ã¨ usato per ridurre il numero di confronti dal potenziale \\(O(n^2)\\) a un insieme piÃ¹ piccolo e verosimile. Si sceglie un blocco â€œnon troppo restrittivoâ€ cosÃ¬ da non perdere troppi possibili match.\n",
    "\n",
    "### 3) Definizione delle Regole di Confronto (Compare)\n",
    "Si istanzia un oggetto `Compare()` di `recordlinkage`, in cui definiamo le metriche usate per confrontare le coppie candidate:\n",
    "\n",
    "- **Somiglianza di stringa (Jaro-Winkler) per `company_name`:**\n",
    "    Calcola un punteggio da 0 (completamente diversi) a 1 (identici). Jaro-Winkler Ã¨ utile per correggere piccoli errori di battitura o variazioni del nome.\n",
    "\n",
    "- **Exact Match per `industry` e `headquarters_city`:**\n",
    "    Se i due record hanno esattamente lo stesso valore, la metrica vale 1, altrimenti 0.\n",
    "\n",
    "In sostanza, cosÃ¬ facendo, potremo valutare se i nomi delle aziende sono molto simili, e allo stesso tempo se `industry` e `headquarters_city` coincidono.\n",
    "\n",
    "### 4) Calcolo della Matrice di SimilaritÃ \n",
    "Viene calcolata la `similarity_matrix` per tutte le coppie candidate prodotte dal blocking. Ogni riga della matrice corrisponde a una coppia \\((record_A, record_B)\\); ogni colonna Ã¨ una metrica (es. `name_sim`, `industry_exact`, `city_exact`). Si stampa la dimensione di questa matrice, cioÃ¨ quante coppie e quante metriche sono state calcolate.\n",
    "\n",
    "**PerchÃ© si fa:** per ogni coppia ritenuta potenzialmente â€œsospettaâ€ (stessa `industry` o nome vicino), si ottengono punteggi che ci aiutano a decidere se la coppia Ã¨ davvero la stessa azienda.\n",
    "\n",
    "### 5) Selezione delle Coppie Considerate â€˜Matchâ€™\n",
    "Dalla matrice di similaritÃ , si estraggono solo le righe che soddisfano certe regole:\n",
    "\n",
    "- Nome simile (`name_sim > 0.95`), oppure\n",
    "- Stesso settore e stessa cittÃ  (`industry_exact == 1` e `city_exact == 1`).\n",
    "\n",
    "Le coppie che rispettano almeno una di queste condizioni vengono prese come â€œmatchâ€. Si stampa quante coppie totali soddisfano i criteri.\n",
    "\n",
    "**PerchÃ© si fa:** abbiamo impostato delle soglie (es. 0.95 su Jaro-Winkler) e regole di abbinamento. A seconda dei dati, si puÃ² decidere di alzare/abbassare le soglie per ottenere piÃ¹ o meno match.\n",
    "\n",
    "### 6) Recupero dei Valori Originali tramite â€œJoinâ€\n",
    "Dopo aver deciso quali coppie sono â€œmatchâ€, si vuole visualizzare i dati originali (il nome, il settore, la cittÃ  per entrambi i record). Per farlo:\n",
    "\n",
    "- Si resetta lâ€™indice (che era una `MultiIndex` di coppie) per ottenere due colonne: `id_left` e `id_right`, corrispondenti alle posizioni dei record nel DataFrame originale.\n",
    "- Si fa un merge con `df` usando `id_left` e poi un altro merge con `id_right`. CosÃ¬ si recuperano i valori effettivi delle colonne `company_name`, `industry`, `headquarters_city` per entrambi i record della coppia (quelli â€œdi sinistraâ€ e â€œdi destraâ€).\n",
    "\n",
    "Ora nel DataFrame finale troviamo colonne come: `company_name_left`, `company_name_right`, `industry_left`, `industry_right`, e cosÃ¬ via, affiancate ai punteggi di similaritÃ .\n",
    "\n",
    "**PerchÃ© si fa:** la tabella di similaritÃ  di base contiene solo i punteggi e gli indici delle coppie. Per controllare â€œa occhioâ€ se i match hanno senso, serve ricostruire i valori testuali originali.\n",
    "\n",
    "### 7) Salvataggio del Risultato in CSV\n",
    "Infine, si esporta il DataFrame risultante (che contiene le coppie abbinate piÃ¹ le colonne left e right) in un file CSV, in modo da avere un report di tutti i match, con i punteggi di somiglianza e i dati affiancati.\n",
    "\n",
    "**PerchÃ© si fa:** questo file finale consente di verificare manualmente (o mostrare al professore/ai colleghi) i match individuati, con la prova testuale delle colonne corrispondenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_21184\\3244916458.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 7358685\n",
      "Dimensioni della similarity_matrix: (7358685, 3)\n",
      "Numero di coppie finali considerate 'match': 112043\n",
      "âœ… File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similaritÃ \n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.8) &  (similarity_matrix['name_sim'] < 0.95) |\n",
    "    ((similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1))\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che Ã¨ una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similaritÃ : name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"âœ… File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avrÃ  le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e cosÃ¬ via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Script completo che esegue il campionamento del CSV `matched_companies_detailed.csv` seguendo i criteri indicati\n",
    "\n",
    "### Passaggi:\n",
    "\n",
    "1. Filtra le coppie con similaritÃ  (`name_sim`) tra 0.6 e 0.7 (o intervallo che preferisci).\n",
    "2. Opzionalmente filtra per diversitÃ  (ad es. `industry_left` != `industry_right` o altre condizioni).\n",
    "3. Applica un campionamento sistematico per ottenere esattamente 2000 coppie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campionamento completato: 1000 righe salvate in 'matched_companies_sampled.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Leggi il CSV originale\n",
    "df = pd.read_csv(\"matched_companies_detailed.csv\")\n",
    "\n",
    "# Normalizza i nomi delle aziende\n",
    "df[\"company_name_left\"] = df[\"company_name_left\"].str.strip().str.lower()\n",
    "df[\"company_name_right\"] = df[\"company_name_right\"].str.strip().str.lower()\n",
    "\n",
    "# Funzione di similaritÃ \n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Calcoliamo la similaritÃ  su ogni riga\n",
    "df[\"name_similarity\"] = df.apply(lambda row: similar(row[\"company_name_left\"], row[\"company_name_right\"]), axis=1)\n",
    "\n",
    "# Filtra per similaritÃ  (tra 0.6 e 0.7 come nella ground truth)\n",
    "filtered_df = df[(df[\"name_similarity\"] >= 0.6) & (df[\"name_similarity\"] <= 0.7)]\n",
    "\n",
    "# Conta le righe rimaste\n",
    "num_rows = len(filtered_df)\n",
    "\n",
    "# Calcola il passo per ottenere ~2000 righe\n",
    "step = max(1, num_rows // 1000)\n",
    "\n",
    "# Campionamento sistematico ogni 'step' righe\n",
    "sampled_df = filtered_df.iloc[::step]\n",
    "\n",
    "# Seleziona solo le prime 2000 righe\n",
    "sampled_df = sampled_df.head(1000)\n",
    "\n",
    "# Salva il CSV campionato\n",
    "sampled_df.to_csv(\"matched_companies_sampled.csv\", index=False)\n",
    "\n",
    "print(f\"Campionamento completato: {len(sampled_df)} righe salvate in 'matched_companies_sampled.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Passaggio 1: Convertire ground_truth.json in CSV\n",
    "\n",
    "Attualmente il file JSON ha questa struttura:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"ground_truth\": [\n",
    "        {\n",
    "            \"1&1\": \"companiesMarketCap_dataset\",\n",
    "            \"1&1 AG\": \"disfold-com\"\n",
    "        },\n",
    "        {\n",
    "            \"AMPLUS\": \"ft-com\",\n",
    "            \"AMPLUS SOLAR\": \"AmbitionBox\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Dobbiamo convertirlo in un formato compatibile con il CSV che abbiamo creato. Un buon formato potrebbe essere:\n",
    "\n",
    "```csv\n",
    "company_a,source_a,company_b,source_b\n",
    "1&1,companiesMarketCap_dataset,1&1 AG,disfold-com\n",
    "AMPLUS,ft-com,AMPLUS SOLAR,AmbitionBox\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# data[\"ground_truth\"] contiene una lista di oggetti\n",
    "# Ognuno di questi oggetti ha esattamente 2 coppie \"nome\": \"fonte\", es:\n",
    "# {\n",
    "#   \"1&1\": \"companiesMarketCap_dataset\",\n",
    "#   \"1&1 AG\": \"disfold-com\"\n",
    "# }\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\"company_a\", \"source_a\", \"company_b\", \"source_b\"])\n",
    "\n",
    "    # Per ogni oggetto in data[\"ground_truth\"], estraiamo i 2 pair\n",
    "    for pair_dict in data[\"ground_truth\"]:\n",
    "        # pair_dict Ã¨ un dizionario, es: {\"1&1\": \"companiesMarketCap_dataset\", \"1&1 AG\": \"disfold-com\"}\n",
    "        items = list(pair_dict.items())  # Convertiamo in lista di tuple [(company, source), (company, source)]\n",
    "        \n",
    "        # Assumiamo che ci siano esattamente 2 coppie\n",
    "        (company_a, source_a) = items[0]\n",
    "        (company_b, source_b) = items[1]\n",
    "\n",
    "        # Scriviamo una riga nel CSV\n",
    "        writer.writerow([company_a, source_a, company_b, source_b])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "---\n",
    "\n",
    "## ðŸ“Š Valutazione dei Risultati Ottenuti\n",
    "\n",
    "In questa sezione, analizzeremo i risultati ottenuti dal processo di matching delle aziende. Valuteremo l'accuratezza e la qualitÃ  dei match identificati, confrontandoli con il ground truth disponibile.\n",
    "\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RISULTATI RECORD LINKAGE (names, MultiIndex) ===\n",
      "Precision: 0.012\n",
      "Recall:    0.059\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recordlinkage.measures import precision, recall, fscore\n",
    "\n",
    "# Ground truth\n",
    "gt_df = pd.read_csv(\"data/ground_truth.csv\")\n",
    "gt_df[\"company_a\"] = gt_df[\"company_a\"].str.strip().str.lower()\n",
    "gt_df[\"company_b\"] = gt_df[\"company_b\"].str.strip().str.lower()\n",
    "\n",
    "true_pairs = {\n",
    "    tuple(sorted([row[\"company_a\"], row[\"company_b\"]]))\n",
    "    for _, row in gt_df.iterrows()\n",
    "}\n",
    "# Convertiamo in MultiIndex\n",
    "true_links = pd.MultiIndex.from_tuples(true_pairs, names=[\"company_left\", \"company_right\"])\n",
    "\n",
    "# Predetti\n",
    "pred_df = pd.read_csv(\"matched_companies_sampled.csv\")\n",
    "pred_df[\"company_name_left\"] = pred_df[\"company_name_left\"].str.strip().str.lower()\n",
    "pred_df[\"company_name_right\"] = pred_df[\"company_name_right\"].str.strip().str.lower()\n",
    "\n",
    "pred_pairs = {\n",
    "    tuple(sorted([row[\"company_name_left\"], row[\"company_name_right\"]]))\n",
    "    for _, row in pred_df.iterrows()\n",
    "}\n",
    "# Convertiamo in MultiIndex\n",
    "pred_links = pd.MultiIndex.from_tuples(pred_pairs, names=[\"company_left\", \"company_right\"])\n",
    "\n",
    "# Calcolo metriche\n",
    "p = precision(true_links, pred_links)\n",
    "r = recall(true_links, pred_links)\n",
    "\n",
    "print(\"=== RISULTATI RECORD LINKAGE (names, MultiIndex) ===\")\n",
    "print(f\"Precision: {p:.3f}\")\n",
    "print(f\"Recall:    {r:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
