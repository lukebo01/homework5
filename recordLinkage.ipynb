{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Riduzione dello Spazio di Confronto (Blocking e Sorted Neighbourhood)\n",
    "\n",
    "Per evitare confronti massivi tra ogni record (un’operazione computazionalmente onerosa), si applicano tecniche per restringere lo spazio di confronto. In questo approccio vengono utilizzate strategie in serie:\n",
    "\n",
    "### Blocking per Settore e per Città\n",
    "- **Descrizione:**  \n",
    "  I record vengono raggruppati in blocchi in base a valori condivisi.\n",
    "  - **Settore:** Le aziende vengono suddivise per settore industriale, poiché quelle dello stesso settore hanno maggiori probabilità di essere simili.\n",
    "  - **Città:** Si applica un ulteriore livello di blocking basato sulla città, restringendo il confronto ai record geograficamente vicini.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Immagina un dataset con aziende nei settori \"Tecnologia\", \"Sanità\" e \"Finanza\", localizzate in città come \"Milano\", \"Roma\" e \"Torino\". Verranno confrontate solo le aziende che appartengono allo stesso settore **e** alla stessa città.\n",
    "\n",
    "### Sorted Neighbourhood\n",
    "- **Descrizione:**  \n",
    "  Dopo aver applicato il blocking, i record vengono ordinati in base al nome dell’azienda. Solo i record vicini, all’interno di una finestra mobile (ad esempio, 5 record consecutivi), vengono confrontati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Considera una lista ordinata alfabeticamente:\n",
    "  - `AlphaTech`\n",
    "  - `Alphatech Solutions`\n",
    "  - `Beta Corp`\n",
    "  - `Gamma Inc`\n",
    "  \n",
    "  Solo \"AlphaTech\" e \"Alphatech Solutions\" verranno confrontati, evidenziando possibili duplicati anche se presentano leggere differenze.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Valutazione della Similarità\n",
    "\n",
    "Una volta ottenute le coppie candidate tramite blocking e sorted neighbourhood, si procede a misurare la somiglianza tra i record.\n",
    "\n",
    "### Confronto del Nome dell’Azienda con Algoritmi di Similarità\n",
    "- **Jaro-Winkler:**  \n",
    "  Questo algoritmo misura il grado di similarità tra due stringhe, gestendo variazioni, errori di battitura e trasposizioni.\n",
    "  \n",
    "  - **Funzionamento:**  \n",
    "    L'algoritmo calcola il numero di caratteri corrispondenti, valuta le trasposizioni e applica un bonus per prefissi comuni.\n",
    "  \n",
    "  - **Esempio pratico:**  \n",
    "    Confrontando \"MARTHA\" e \"MARHTA\", nonostante l'inversione di \"T\" e \"H\", il punteggio potrebbe essere alto (ad esempio, 0.94), indicando una forte somiglianza.\n",
    "\n",
    "### Confronti Esatti per Altri Attributi\n",
    "- **Descrizione:**  \n",
    "  Per attributi come settore e città, si utilizza un confronto esatto: due record sono considerati corrispondenti solo se i valori sono identici.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Se due record indicano \"Tecnologia\" come settore e \"Roma\" come città, il confronto esatto restituisce una corrispondenza perfetta (valore 1). Se anche uno solo dei due valori differisce, la corrispondenza fallisce (valore 0).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Definizione di Regole per il Matching\n",
    "\n",
    "Dopo aver calcolato i punteggi di similarità per ogni coppia, è necessario definire regole per decidere se due record rappresentano la stessa entità.\n",
    "\n",
    "### Impostazione di Soglie di Similarità\n",
    "- **Descrizione:**  \n",
    "  Si stabiliscono delle soglie minime che il punteggio di similarità deve raggiungere affinché una coppia sia considerata un match.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Si può decidere che un punteggio Jaro-Winkler superiore a 0.90 indichi che i nomi sono sufficientemente simili per suggerire un duplicato.\n",
    "\n",
    "### Combinazione di Condizioni su Più Attributi\n",
    "- **Descrizione:**  \n",
    "  Le regole di matching combinano il punteggio del nome con confronti esatti per altri attributi (settore e città).\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Una coppia di record viene considerata un match se:\n",
    "  - **Opzione 1:** Il punteggio del nome è superiore a 0.90;  \n",
    "    **oppure**\n",
    "  - **Opzione 2:** Il punteggio del nome è compreso tra 0.80 e 0.92 **e** sia il settore che la città coincidono esattamente.\n",
    "  \n",
    "  Questo approccio riduce i falsi positivi, identificando come match solo le coppie con una forte corrispondenza in tutti i campi critici.\n",
    "\n",
    "### Bilanciamento tra Precisione e Recall\n",
    "- **Descrizione:**  \n",
    "  Le soglie e le regole vengono ottimizzate per bilanciare:\n",
    "  - **Precisione:** La percentuale di match corretti tra quelli identificati.\n",
    "  - **Recall:** La percentuale di duplicati reali individuati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Soglie troppo rigide possono portare a perdere duplicati reali (basso recall), mentre soglie troppo permissive possono includere troppi falsi positivi (bassa precisione). Un tuning accurato consente di raggiungere un equilibrio ottimale.\n",
    "\n",
    "---\n",
    "\n",
    "Questa spiegazione mostra come:\n",
    "- Le tecniche di **blocking** (per settore e città) e **sorted neighbourhood** riducano il numero di confronti,\n",
    "- L'algoritmo **Jaro-Winkler** (insieme a confronti esatti) valuti la similarità tra record,\n",
    "- E le regole di matching combinino questi elementi per identificare duplicati in modo efficace, bilanciando precisione e recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_18428\\2525519434.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 9515230\n",
      "Dimensioni della similarity_matrix: (9515230, 3)\n",
      "Numero di coppie finali considerate 'match': 118429\n",
      "✅ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similarità\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92) |\n",
    "    (similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che è una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similarità: name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"✅ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avrà le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e così via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convertire ground_truth.json in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\n",
    "        \"company_a\", \"industry_a\", \"country_a\", \"source_a\",\n",
    "        \"company_b\", \"industry_b\", \"country_b\", \"source_b\",\n",
    "        \"label\"\n",
    "    ])\n",
    "\n",
    "    # Per ogni record in data[\"ground_truth\"]\n",
    "    for record in data[\"ground_truth\"]:\n",
    "        pairs = record[\"pairs\"]\n",
    "        # Assumiamo che pairs contenga esattamente 2 elementi:\n",
    "        pair_a, pair_b = pairs[0], pairs[1]\n",
    "\n",
    "        # Estraiamo i valori per la prima azienda\n",
    "        company_a = pair_a.get(\"company-name\", \"\")\n",
    "        industry_a = pair_a.get(\"industry\", \"\")\n",
    "        country_a = pair_a.get(\"country\", \"\")\n",
    "        source_a = pair_a.get(\"source\", \"\")\n",
    "\n",
    "        # Estraiamo i valori per la seconda azienda\n",
    "        company_b = pair_b.get(\"company-name\", \"\")\n",
    "        industry_b = pair_b.get(\"industry\", \"\")\n",
    "        country_b = pair_b.get(\"country\", \"\")\n",
    "        source_b = pair_b.get(\"source\", \"\")\n",
    "\n",
    "        # Se il campo industry è una lista, uniamo gli elementi in una stringa\n",
    "        if isinstance(industry_a, list):\n",
    "            industry_a = \"; \".join(industry_a)\n",
    "        if isinstance(industry_b, list):\n",
    "            industry_b = \"; \".join(industry_b)\n",
    "\n",
    "        # Convertiamo eventuali None in stringhe vuote\n",
    "        country_a = country_a or \"\"\n",
    "        country_b = country_b or \"\"\n",
    "        industry_a = industry_a or \"\"\n",
    "        industry_b = industry_b or \"\"\n",
    "\n",
    "        # Impostiamo la label: 1 se match è true, 0 se false\n",
    "        label = 1 if record.get(\"match\", False) else 0\n",
    "\n",
    "        # Scriviamo la riga nel CSV\n",
    "        writer.writerow([\n",
    "            company_a, industry_a, country_a, source_a,\n",
    "            company_b, industry_b, country_b, source_b,\n",
    "            label\n",
    "        ])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle metriche di recision Recall e F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie in pairwise: 98726\n",
      "Numero di coppie in ground truth: 212\n",
      "Numero di coppie in ground truth con label a 1: 80\n",
      "Numero di coppie in intersezione: 197\n",
      "Numero di coppie nell'intersezione con label 1: 73\n",
      "Precision: 0.3706\n",
      "Recall: 0.9125\n",
      "F1-Score: 0.5271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path dei file (aggiorna con i percorsi reali)\n",
    "pairwise_file = 'matched_companies_detailed.csv'\n",
    "groundtruth_file = 'data/ground_truth.csv'\n",
    "\n",
    "# Caricamento dei file\n",
    "pairwise = pd.read_csv(pairwise_file)\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# Funzione di supporto per normalizzare i nomi di società (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# Funzione per ottenere una tupla ordinata, così che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# Creiamo la colonna 'normalized_pair' in entrambi i dataset\n",
    "pairwise['normalized_pair'] = pairwise.apply(\n",
    "    lambda x: normalize_pair(x, 'company_name_left', 'company_name_right'), axis=1\n",
    ")\n",
    "groundtruth['normalized_pair'] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, 'company_a', 'company_b'), axis=1\n",
    ")\n",
    "\n",
    "# Convertiamo in insiemi per confronto\n",
    "pairwise_set = set(pairwise['normalized_pair'])\n",
    "groundtruth_set = set(groundtruth['normalized_pair'])\n",
    "\n",
    "# Intersezione tra le coppie del dataset pairwise e quelle della ground truth (tutte, indipendentemente dalla label)\n",
    "intersection = pairwise_set.intersection(groundtruth_set)\n",
    "\n",
    "# Filtriamo la ground truth per ottenere solo le coppie con label 1 (cioè i match veri)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth['label'] == 1]['normalized_pair'])\n",
    "\n",
    "# Calcoliamo il numero di coppie dell'intersezione che hanno label 1\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# Calcolo delle metriche:\n",
    "# - Precisione: fra le coppie previste (cioè quelle in intersezione), quanti sono corretti (label=1)\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "# - Recall: fra tutte le coppie corrette presenti in ground truth, quanti sono stati trovati\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output dei risultati\n",
    "print(f\"Numero di coppie in pairwise: {len(pairwise_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f'Numero di coppie in ground truth con label a 1: {len(groundtruth_true_set)}')\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie nell'intersezione con label 1: {tp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle Metriche dei Risultati del Transformer\n",
    "\n",
    "Il seguente script è utilizzato per calcolare le metriche di precisione, recall e F1-score dei risultati ottenuti dal modello Transformer per il matching delle entità. \n",
    "\n",
    "Questo script permette di valutare l'efficacia del modello Transformer nel riconoscere correttamente le coppie di entità duplicate, fornendo metriche chiave per l'analisi delle performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 6155\n",
      "Numero di coppie candidate: 559844\n",
      "Dimensioni della similarity_matrix: (559844, 1)\n",
      "Numero di coppie filtrate per il Transformer: 71883\n",
      "✅ Blocking e filtraggio completati! Coppie salvate in `filtered_pairs.tsv`\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1️⃣ Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file, low_memory=False, dtype=str)  # Evita problemi di tipi misti\n",
    "df = df[['company_name', 'industry', 'headquarters_city']].dropna()\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# Resettiamo l'indice e creiamo una colonna ID univoca\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"id\"] = df.index  # Colonna numerica per identificare univocamente i record\n",
    "\n",
    "# 2️⃣ Creazione di un blocking efficace (simile alla vecchia pipeline)\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))  # Blocca per settore\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))  # Blocca per città\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=3))  # Simile alla tua vecchia pipeline\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3️⃣ Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "\n",
    "# 4️⃣ Calcolo della similarità\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5️⃣ Selezioniamo coppie con nome simile (applichiamo il filtraggio come la vecchia pipeline)\n",
    "filtered_matches = similarity_matrix[(similarity_matrix['name_sim'] > 0.60)]\n",
    "print(f\"Numero di coppie filtrate per il Transformer: {len(filtered_matches)}\")\n",
    "\n",
    "# 6️⃣ Convertiamo in formato TSV per il Transformer\n",
    "filtered_matches = filtered_matches.reset_index()\n",
    "\n",
    "# Ora possiamo usare la colonna `id` senza problemi di duplicati\n",
    "filtered_matches[\"sentence1\"] = df.loc[filtered_matches[\"level_0\"], \"company_name\"].values\n",
    "filtered_matches[\"sentence2\"] = df.loc[filtered_matches[\"level_1\"], \"company_name\"].values\n",
    "filtered_matches[\"label\"] = \"?\"  # Lasciamo il modello decidere\n",
    "\n",
    "# 7️⃣ Salviamo il file TSV nel formato corretto\n",
    "filtered_matches[[\"level_0\", \"sentence1\", \"sentence2\", \"label\"]].to_csv(\"entity-matching-transformer/filtered_pairs.tsv\", sep=\"\\t\", index=False, header=[\"id\", \"sentence1\", \"sentence2\", \"label\"])\n",
    "\n",
    "print(\"✅ Blocking e filtraggio completati! Coppie salvate in `filtered_pairs.tsv`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie predette come match dal modello: 3307\n",
      "Numero di coppie in ground truth: 212\n",
      "Numero di coppie in ground truth con label 1: 80\n",
      "Numero di coppie in intersezione: 0\n",
      "Numero di coppie corrette (True Positives): 0\n",
      "📌 Precision: 0.0000\n",
      "📌 Recall: 0.0000\n",
      "📌 F1-Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📂 Percorsi dei file (aggiorna con i percorsi reali)\n",
    "model_output_file = \"entity-matching-transformer/matching_results.tsv\"  # File generato dal modello\n",
    "groundtruth_file = \"data/ground_truth.csv\"  # Ground truth\n",
    "\n",
    "# 📥 Caricamento dei file\n",
    "model_results = pd.read_csv(model_output_file, sep=\"\\t\")\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# 🔍 Normalizzazione dei nomi di società (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# 📌 Funzione per ottenere una tupla ordinata, così che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# 📊 Filtriamo solo le coppie che il modello ha predetto come match (label 1)\n",
    "model_results = model_results[model_results[\"predicted_label\"] == 1]\n",
    "\n",
    "# 🛠 Creiamo la colonna 'normalized_pair' nei dataset\n",
    "model_results[\"normalized_pair\"] = model_results.apply(\n",
    "    lambda x: normalize_pair(x, \"sentence1\", \"sentence2\"), axis=1\n",
    ")\n",
    "groundtruth[\"normalized_pair\"] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, \"company_a\", \"company_b\"), axis=1\n",
    ")\n",
    "\n",
    "# 🔀 Convertiamo in insiemi per confronto\n",
    "model_set = set(model_results[\"normalized_pair\"])\n",
    "groundtruth_set = set(groundtruth[\"normalized_pair\"])\n",
    "\n",
    "# 🔗 Intersezione tra le coppie predette e quelle nella ground truth\n",
    "intersection = model_set.intersection(groundtruth_set)\n",
    "\n",
    "# 🎯 Filtriamo la ground truth per ottenere solo i veri match (label = 1)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth[\"label\"] == 1][\"normalized_pair\"])\n",
    "\n",
    "# ✅ Calcoliamo il numero di True Positives (coppie predette che sono davvero match)\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# 📊 Calcolo delle metriche:\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# 📢 Output dei risultati\n",
    "print(f\"Numero di coppie predette come match dal modello: {len(model_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f\"Numero di coppie in ground truth con label 1: {len(groundtruth_true_set)}\")\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie corrette (True Positives): {tp}\")\n",
    "print(f\"📌 Precision: {precision:.4f}\")\n",
    "print(f\"📌 Recall: {recall:.4f}\")\n",
    "print(f\"📌 F1-Score: {f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
