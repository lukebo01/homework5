{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Riduzione dello Spazio di Confronto (Blocking e Sorted Neighbourhood)\n",
    "\n",
    "Per evitare confronti massivi tra ogni record (unâ€™operazione computazionalmente onerosa), si applicano tecniche per restringere lo spazio di confronto. In questo approccio vengono utilizzate strategie in serie:\n",
    "\n",
    "### Blocking per Settore e per CittÃ \n",
    "- **Descrizione:**  \n",
    "  I record vengono raggruppati in blocchi in base a valori condivisi.\n",
    "  - **Settore:** Le aziende vengono suddivise per settore industriale, poichÃ© quelle dello stesso settore hanno maggiori probabilitÃ  di essere simili.\n",
    "  - **CittÃ :** Si applica un ulteriore livello di blocking basato sulla cittÃ , restringendo il confronto ai record geograficamente vicini.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Immagina un dataset con aziende nei settori \"Tecnologia\", \"SanitÃ \" e \"Finanza\", localizzate in cittÃ  come \"Milano\", \"Roma\" e \"Torino\". Verranno confrontate solo le aziende che appartengono allo stesso settore **e** alla stessa cittÃ .\n",
    "\n",
    "### Sorted Neighbourhood\n",
    "- **Descrizione:**  \n",
    "  Dopo aver applicato il blocking, i record vengono ordinati in base al nome dellâ€™azienda. Solo i record vicini, allâ€™interno di una finestra mobile (ad esempio, 5 record consecutivi), vengono confrontati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Considera una lista ordinata alfabeticamente:\n",
    "  - `AlphaTech`\n",
    "  - `Alphatech Solutions`\n",
    "  - `Beta Corp`\n",
    "  - `Gamma Inc`\n",
    "  \n",
    "  Solo \"AlphaTech\" e \"Alphatech Solutions\" verranno confrontati, evidenziando possibili duplicati anche se presentano leggere differenze.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Valutazione della SimilaritÃ \n",
    "\n",
    "Una volta ottenute le coppie candidate tramite blocking e sorted neighbourhood, si procede a misurare la somiglianza tra i record.\n",
    "\n",
    "### Confronto del Nome dellâ€™Azienda con Algoritmi di SimilaritÃ \n",
    "- **Jaro-Winkler:**  \n",
    "  Questo algoritmo misura il grado di similaritÃ  tra due stringhe, gestendo variazioni, errori di battitura e trasposizioni.\n",
    "  \n",
    "  - **Funzionamento:**  \n",
    "    L'algoritmo calcola il numero di caratteri corrispondenti, valuta le trasposizioni e applica un bonus per prefissi comuni.\n",
    "  \n",
    "  - **Esempio pratico:**  \n",
    "    Confrontando \"MARTHA\" e \"MARHTA\", nonostante l'inversione di \"T\" e \"H\", il punteggio potrebbe essere alto (ad esempio, 0.94), indicando una forte somiglianza.\n",
    "\n",
    "### Confronti Esatti per Altri Attributi\n",
    "- **Descrizione:**  \n",
    "  Per attributi come settore e cittÃ , si utilizza un confronto esatto: due record sono considerati corrispondenti solo se i valori sono identici.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Se due record indicano \"Tecnologia\" come settore e \"Roma\" come cittÃ , il confronto esatto restituisce una corrispondenza perfetta (valore 1). Se anche uno solo dei due valori differisce, la corrispondenza fallisce (valore 0).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Definizione di Regole per il Matching\n",
    "\n",
    "Dopo aver calcolato i punteggi di similaritÃ  per ogni coppia, Ã¨ necessario definire regole per decidere se due record rappresentano la stessa entitÃ .\n",
    "\n",
    "### Impostazione di Soglie di SimilaritÃ \n",
    "- **Descrizione:**  \n",
    "  Si stabiliscono delle soglie minime che il punteggio di similaritÃ  deve raggiungere affinchÃ© una coppia sia considerata un match.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Si puÃ² decidere che un punteggio Jaro-Winkler superiore a 0.90 indichi che i nomi sono sufficientemente simili per suggerire un duplicato.\n",
    "\n",
    "### Combinazione di Condizioni su PiÃ¹ Attributi\n",
    "- **Descrizione:**  \n",
    "  Le regole di matching combinano il punteggio del nome con confronti esatti per altri attributi (settore e cittÃ ).\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Una coppia di record viene considerata un match se:\n",
    "  - **Opzione 1:** Il punteggio del nome Ã¨ superiore a 0.90;  \n",
    "    **oppure**\n",
    "  - **Opzione 2:** Il punteggio del nome Ã¨ compreso tra 0.80 e 0.92 **e** sia il settore che la cittÃ  coincidono esattamente.\n",
    "  \n",
    "  Questo approccio riduce i falsi positivi, identificando come match solo le coppie con una forte corrispondenza in tutti i campi critici.\n",
    "\n",
    "### Bilanciamento tra Precisione e Recall\n",
    "- **Descrizione:**  \n",
    "  Le soglie e le regole vengono ottimizzate per bilanciare:\n",
    "  - **Precisione:** La percentuale di match corretti tra quelli identificati.\n",
    "  - **Recall:** La percentuale di duplicati reali individuati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Soglie troppo rigide possono portare a perdere duplicati reali (basso recall), mentre soglie troppo permissive possono includere troppi falsi positivi (bassa precisione). Un tuning accurato consente di raggiungere un equilibrio ottimale.\n",
    "\n",
    "---\n",
    "\n",
    "Questa spiegazione mostra come:\n",
    "- Le tecniche di **blocking** (per settore e cittÃ ) e **sorted neighbourhood** riducano il numero di confronti,\n",
    "- L'algoritmo **Jaro-Winkler** (insieme a confronti esatti) valuti la similaritÃ  tra record,\n",
    "- E le regole di matching combinino questi elementi per identificare duplicati in modo efficace, bilanciando precisione e recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_18428\\2525519434.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 9515230\n",
      "Dimensioni della similarity_matrix: (9515230, 3)\n",
      "Numero di coppie finali considerate 'match': 118429\n",
      "âœ… File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similaritÃ \n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92) |\n",
    "    (similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che Ã¨ una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similaritÃ : name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"âœ… File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avrÃ  le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e cosÃ¬ via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convertire ground_truth.json in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\n",
    "        \"company_a\", \"industry_a\", \"country_a\", \"source_a\",\n",
    "        \"company_b\", \"industry_b\", \"country_b\", \"source_b\",\n",
    "        \"label\"\n",
    "    ])\n",
    "\n",
    "    # Per ogni record in data[\"ground_truth\"]\n",
    "    for record in data[\"ground_truth\"]:\n",
    "        pairs = record[\"pairs\"]\n",
    "        # Assumiamo che pairs contenga esattamente 2 elementi:\n",
    "        pair_a, pair_b = pairs[0], pairs[1]\n",
    "\n",
    "        # Estraiamo i valori per la prima azienda\n",
    "        company_a = pair_a.get(\"company-name\", \"\")\n",
    "        industry_a = pair_a.get(\"industry\", \"\")\n",
    "        country_a = pair_a.get(\"country\", \"\")\n",
    "        source_a = pair_a.get(\"source\", \"\")\n",
    "\n",
    "        # Estraiamo i valori per la seconda azienda\n",
    "        company_b = pair_b.get(\"company-name\", \"\")\n",
    "        industry_b = pair_b.get(\"industry\", \"\")\n",
    "        country_b = pair_b.get(\"country\", \"\")\n",
    "        source_b = pair_b.get(\"source\", \"\")\n",
    "\n",
    "        # Se il campo industry Ã¨ una lista, uniamo gli elementi in una stringa\n",
    "        if isinstance(industry_a, list):\n",
    "            industry_a = \"; \".join(industry_a)\n",
    "        if isinstance(industry_b, list):\n",
    "            industry_b = \"; \".join(industry_b)\n",
    "\n",
    "        # Convertiamo eventuali None in stringhe vuote\n",
    "        country_a = country_a or \"\"\n",
    "        country_b = country_b or \"\"\n",
    "        industry_a = industry_a or \"\"\n",
    "        industry_b = industry_b or \"\"\n",
    "\n",
    "        # Impostiamo la label: 1 se match Ã¨ true, 0 se false\n",
    "        label = 1 if record.get(\"match\", False) else 0\n",
    "\n",
    "        # Scriviamo la riga nel CSV\n",
    "        writer.writerow([\n",
    "            company_a, industry_a, country_a, source_a,\n",
    "            company_b, industry_b, country_b, source_b,\n",
    "            label\n",
    "        ])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle metriche di recision Recall e F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie in pairwise: 98726\n",
      "Numero di coppie in ground truth: 212\n",
      "Numero di coppie in ground truth con label a 1: 80\n",
      "Numero di coppie in intersezione: 197\n",
      "Numero di coppie nell'intersezione con label 1: 73\n",
      "Precision: 0.3706\n",
      "Recall: 0.9125\n",
      "F1-Score: 0.5271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path dei file (aggiorna con i percorsi reali)\n",
    "pairwise_file = 'matched_companies_detailed.csv'\n",
    "groundtruth_file = 'data/ground_truth.csv'\n",
    "\n",
    "# Caricamento dei file\n",
    "pairwise = pd.read_csv(pairwise_file)\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# Funzione di supporto per normalizzare i nomi di societÃ  (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# Funzione per ottenere una tupla ordinata, cosÃ¬ che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# Creiamo la colonna 'normalized_pair' in entrambi i dataset\n",
    "pairwise['normalized_pair'] = pairwise.apply(\n",
    "    lambda x: normalize_pair(x, 'company_name_left', 'company_name_right'), axis=1\n",
    ")\n",
    "groundtruth['normalized_pair'] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, 'company_a', 'company_b'), axis=1\n",
    ")\n",
    "\n",
    "# Convertiamo in insiemi per confronto\n",
    "pairwise_set = set(pairwise['normalized_pair'])\n",
    "groundtruth_set = set(groundtruth['normalized_pair'])\n",
    "\n",
    "# Intersezione tra le coppie del dataset pairwise e quelle della ground truth (tutte, indipendentemente dalla label)\n",
    "intersection = pairwise_set.intersection(groundtruth_set)\n",
    "\n",
    "# Filtriamo la ground truth per ottenere solo le coppie con label 1 (cioÃ¨ i match veri)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth['label'] == 1]['normalized_pair'])\n",
    "\n",
    "# Calcoliamo il numero di coppie dell'intersezione che hanno label 1\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# Calcolo delle metriche:\n",
    "# - Precisione: fra le coppie previste (cioÃ¨ quelle in intersezione), quanti sono corretti (label=1)\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "# - Recall: fra tutte le coppie corrette presenti in ground truth, quanti sono stati trovati\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output dei risultati\n",
    "print(f\"Numero di coppie in pairwise: {len(pairwise_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f'Numero di coppie in ground truth con label a 1: {len(groundtruth_true_set)}')\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie nell'intersezione con label 1: {tp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle Metriche dei Risultati del Transformer\n",
    "\n",
    "Il seguente script Ã¨ utilizzato per calcolare le metriche di precisione, recall e F1-score dei risultati ottenuti dal modello Transformer per il matching delle entitÃ . \n",
    "\n",
    "Questo script permette di valutare l'efficacia del modello Transformer nel riconoscere correttamente le coppie di entitÃ  duplicate, fornendo metriche chiave per l'analisi delle performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 6155\n",
      "Numero di coppie candidate: 559844\n",
      "Dimensioni della similarity_matrix: (559844, 1)\n",
      "Numero di coppie filtrate per il Transformer: 71883\n",
      "âœ… Blocking e filtraggio completati! Coppie salvate in `filtered_pairs.tsv`\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1ï¸âƒ£ Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file, low_memory=False, dtype=str)  # Evita problemi di tipi misti\n",
    "df = df[['company_name', 'industry', 'headquarters_city']].dropna()\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# Resettiamo l'indice e creiamo una colonna ID univoca\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"id\"] = df.index  # Colonna numerica per identificare univocamente i record\n",
    "\n",
    "# 2ï¸âƒ£ Creazione di un blocking efficace (simile alla vecchia pipeline)\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))  # Blocca per settore\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))  # Blocca per cittÃ \n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=3))  # Simile alla tua vecchia pipeline\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3ï¸âƒ£ Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "\n",
    "# 4ï¸âƒ£ Calcolo della similaritÃ \n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5ï¸âƒ£ Selezioniamo coppie con nome simile (applichiamo il filtraggio come la vecchia pipeline)\n",
    "filtered_matches = similarity_matrix[(similarity_matrix['name_sim'] > 0.60)]\n",
    "print(f\"Numero di coppie filtrate per il Transformer: {len(filtered_matches)}\")\n",
    "\n",
    "# 6ï¸âƒ£ Convertiamo in formato TSV per il Transformer\n",
    "filtered_matches = filtered_matches.reset_index()\n",
    "\n",
    "# Ora possiamo usare la colonna `id` senza problemi di duplicati\n",
    "filtered_matches[\"sentence1\"] = df.loc[filtered_matches[\"level_0\"], \"company_name\"].values\n",
    "filtered_matches[\"sentence2\"] = df.loc[filtered_matches[\"level_1\"], \"company_name\"].values\n",
    "filtered_matches[\"label\"] = \"?\"  # Lasciamo il modello decidere\n",
    "\n",
    "# 7ï¸âƒ£ Salviamo il file TSV nel formato corretto\n",
    "filtered_matches[[\"level_0\", \"sentence1\", \"sentence2\", \"label\"]].to_csv(\"entity-matching-transformer/filtered_pairs.tsv\", sep=\"\\t\", index=False, header=[\"id\", \"sentence1\", \"sentence2\", \"label\"])\n",
    "\n",
    "print(\"âœ… Blocking e filtraggio completati! Coppie salvate in `filtered_pairs.tsv`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie predette come match dal modello: 3307\n",
      "Numero di coppie in ground truth: 212\n",
      "Numero di coppie in ground truth con label 1: 80\n",
      "Numero di coppie in intersezione: 0\n",
      "Numero di coppie corrette (True Positives): 0\n",
      "ğŸ“Œ Precision: 0.0000\n",
      "ğŸ“Œ Recall: 0.0000\n",
      "ğŸ“Œ F1-Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ“‚ Percorsi dei file (aggiorna con i percorsi reali)\n",
    "model_output_file = \"entity-matching-transformer/matching_results.tsv\"  # File generato dal modello\n",
    "groundtruth_file = \"data/ground_truth.csv\"  # Ground truth\n",
    "\n",
    "# ğŸ“¥ Caricamento dei file\n",
    "model_results = pd.read_csv(model_output_file, sep=\"\\t\")\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# ğŸ” Normalizzazione dei nomi di societÃ  (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# ğŸ“Œ Funzione per ottenere una tupla ordinata, cosÃ¬ che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# ğŸ“Š Filtriamo solo le coppie che il modello ha predetto come match (label 1)\n",
    "model_results = model_results[model_results[\"predicted_label\"] == 1]\n",
    "\n",
    "# ğŸ›  Creiamo la colonna 'normalized_pair' nei dataset\n",
    "model_results[\"normalized_pair\"] = model_results.apply(\n",
    "    lambda x: normalize_pair(x, \"sentence1\", \"sentence2\"), axis=1\n",
    ")\n",
    "groundtruth[\"normalized_pair\"] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, \"company_a\", \"company_b\"), axis=1\n",
    ")\n",
    "\n",
    "# ğŸ”€ Convertiamo in insiemi per confronto\n",
    "model_set = set(model_results[\"normalized_pair\"])\n",
    "groundtruth_set = set(groundtruth[\"normalized_pair\"])\n",
    "\n",
    "# ğŸ”— Intersezione tra le coppie predette e quelle nella ground truth\n",
    "intersection = model_set.intersection(groundtruth_set)\n",
    "\n",
    "# ğŸ¯ Filtriamo la ground truth per ottenere solo i veri match (label = 1)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth[\"label\"] == 1][\"normalized_pair\"])\n",
    "\n",
    "# âœ… Calcoliamo il numero di True Positives (coppie predette che sono davvero match)\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# ğŸ“Š Calcolo delle metriche:\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# ğŸ“¢ Output dei risultati\n",
    "print(f\"Numero di coppie predette come match dal modello: {len(model_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f\"Numero di coppie in ground truth con label 1: {len(groundtruth_true_set)}\")\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie corrette (True Positives): {tp}\")\n",
    "print(f\"ğŸ“Œ Precision: {precision:.4f}\")\n",
    "print(f\"ğŸ“Œ Recall: {recall:.4f}\")\n",
    "print(f\"ğŸ“Œ F1-Score: {f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
