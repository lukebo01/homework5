{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Riduzione dello Spazio di Confronto (Blocking e Sorted Neighbourhood)\n",
    "\n",
    "Per evitare confronti massivi tra ogni record (un’operazione computazionalmente onerosa), si applicano tecniche per restringere lo spazio di confronto. In questo approccio vengono utilizzate strategie in serie:\n",
    "\n",
    "### Blocking per Settore e per Città\n",
    "- **Descrizione:**  \n",
    "  I record vengono raggruppati in blocchi in base a valori condivisi.\n",
    "  - **Settore:** Le aziende vengono suddivise per settore industriale, poiché quelle dello stesso settore hanno maggiori probabilità di essere simili.\n",
    "  - **Città:** Si applica un ulteriore livello di blocking basato sulla città, restringendo il confronto ai record geograficamente vicini.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Immagina un dataset con aziende nei settori \"Tecnologia\", \"Sanità\" e \"Finanza\", localizzate in città come \"Milano\", \"Roma\" e \"Torino\". Verranno confrontate solo le aziende che appartengono allo stesso settore **e** alla stessa città.\n",
    "\n",
    "### Sorted Neighbourhood\n",
    "- **Descrizione:**  \n",
    "  Dopo aver applicato il blocking, i record vengono ordinati in base al nome dell’azienda. Solo i record vicini, all’interno di una finestra mobile (ad esempio, 5 record consecutivi), vengono confrontati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Considera una lista ordinata alfabeticamente:\n",
    "  - `AlphaTech`\n",
    "  - `Alphatech Solutions`\n",
    "  - `Beta Corp`\n",
    "  - `Gamma Inc`\n",
    "  \n",
    "  Solo \"AlphaTech\" e \"Alphatech Solutions\" verranno confrontati, evidenziando possibili duplicati anche se presentano leggere differenze.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Valutazione della Similarità\n",
    "\n",
    "Una volta ottenute le coppie candidate tramite blocking e sorted neighbourhood, si procede a misurare la somiglianza tra i record.\n",
    "\n",
    "### Confronto del Nome dell’Azienda con Algoritmi di Similarità\n",
    "- **Jaro-Winkler:**  \n",
    "  Questo algoritmo misura il grado di similarità tra due stringhe, gestendo variazioni, errori di battitura e trasposizioni.\n",
    "  \n",
    "  - **Funzionamento:**  \n",
    "    L'algoritmo calcola il numero di caratteri corrispondenti, valuta le trasposizioni e applica un bonus per prefissi comuni.\n",
    "  \n",
    "  - **Esempio pratico:**  \n",
    "    Confrontando \"MARTHA\" e \"MARHTA\", nonostante l'inversione di \"T\" e \"H\", il punteggio potrebbe essere alto (ad esempio, 0.94), indicando una forte somiglianza.\n",
    "\n",
    "### Confronti Esatti per Altri Attributi\n",
    "- **Descrizione:**  \n",
    "  Per attributi come settore e città, si utilizza un confronto esatto: due record sono considerati corrispondenti solo se i valori sono identici.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Se due record indicano \"Tecnologia\" come settore e \"Roma\" come città, il confronto esatto restituisce una corrispondenza perfetta (valore 1). Se anche uno solo dei due valori differisce, la corrispondenza fallisce (valore 0).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Definizione di Regole per il Matching\n",
    "\n",
    "Dopo aver calcolato i punteggi di similarità per ogni coppia, è necessario definire regole per decidere se due record rappresentano la stessa entità.\n",
    "\n",
    "### Impostazione di Soglie di Similarità\n",
    "- **Descrizione:**  \n",
    "  Si stabiliscono delle soglie minime che il punteggio di similarità deve raggiungere affinché una coppia sia considerata un match.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Si può decidere che un punteggio Jaro-Winkler superiore a 0.90 indichi che i nomi sono sufficientemente simili per suggerire un duplicato.\n",
    "\n",
    "### Combinazione di Condizioni su Più Attributi\n",
    "- **Descrizione:**  \n",
    "  Le regole di matching combinano il punteggio del nome con confronti esatti per altri attributi (settore e città).\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Una coppia di record viene considerata un match se:\n",
    "  - **Opzione 1:** Il punteggio del nome è superiore a 0.90;  \n",
    "    **oppure**\n",
    "  - **Opzione 2:** Il punteggio del nome è compreso tra 0.80 e 0.92 **e** sia il settore che la città coincidono esattamente.\n",
    "  \n",
    "  Questo approccio riduce i falsi positivi, identificando come match solo le coppie con una forte corrispondenza in tutti i campi critici.\n",
    "\n",
    "### Bilanciamento tra Precisione e Recall\n",
    "- **Descrizione:**  \n",
    "  Le soglie e le regole vengono ottimizzate per bilanciare:\n",
    "  - **Precisione:** La percentuale di match corretti tra quelli identificati.\n",
    "  - **Recall:** La percentuale di duplicati reali individuati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Soglie troppo rigide possono portare a perdere duplicati reali (basso recall), mentre soglie troppo permissive possono includere troppi falsi positivi (bassa precisione). Un tuning accurato consente di raggiungere un equilibrio ottimale.\n",
    "\n",
    "---\n",
    "\n",
    "Questa spiegazione mostra come:\n",
    "- Le tecniche di **blocking** (per settore e città) e **sorted neighbourhood** riducano il numero di confronti,\n",
    "- L'algoritmo **Jaro-Winkler** (insieme a confronti esatti) valuti la similarità tra record,\n",
    "- E le regole di matching combinino questi elementi per identificare duplicati in modo efficace, bilanciando precisione e recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_8332\\2525519434.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 9515230\n",
      "Dimensioni della similarity_matrix: (9515230, 3)\n",
      "Numero di coppie finali considerate 'match': 118429\n",
      "✅ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similarità\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92) |\n",
    "    (similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che è una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similarità: name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"✅ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avrà le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e così via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convertire ground_truth.json in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\n",
    "        \"company_a\", \"industry_a\", \"country_a\", \"source_a\",\n",
    "        \"company_b\", \"industry_b\", \"country_b\", \"source_b\",\n",
    "        \"label\"\n",
    "    ])\n",
    "\n",
    "    # Per ogni record in data[\"ground_truth\"]\n",
    "    for record in data[\"ground_truth\"]:\n",
    "        pairs = record[\"pairs\"]\n",
    "        # Assumiamo che pairs contenga esattamente 2 elementi:\n",
    "        pair_a, pair_b = pairs[0], pairs[1]\n",
    "\n",
    "        # Estraiamo i valori per la prima azienda\n",
    "        company_a = pair_a.get(\"company-name\", \"\")\n",
    "        industry_a = pair_a.get(\"industry\", \"\")\n",
    "        country_a = pair_a.get(\"country\", \"\")\n",
    "        source_a = pair_a.get(\"source\", \"\")\n",
    "\n",
    "        # Estraiamo i valori per la seconda azienda\n",
    "        company_b = pair_b.get(\"company-name\", \"\")\n",
    "        industry_b = pair_b.get(\"industry\", \"\")\n",
    "        country_b = pair_b.get(\"country\", \"\")\n",
    "        source_b = pair_b.get(\"source\", \"\")\n",
    "\n",
    "        # Se il campo industry è una lista, uniamo gli elementi in una stringa\n",
    "        if isinstance(industry_a, list):\n",
    "            industry_a = \"; \".join(industry_a)\n",
    "        if isinstance(industry_b, list):\n",
    "            industry_b = \"; \".join(industry_b)\n",
    "\n",
    "        # Convertiamo eventuali None in stringhe vuote\n",
    "        country_a = country_a or \"\"\n",
    "        country_b = country_b or \"\"\n",
    "        industry_a = industry_a or \"\"\n",
    "        industry_b = industry_b or \"\"\n",
    "\n",
    "        # Impostiamo la label: 1 se match è true, 0 se false\n",
    "        label = 1 if record.get(\"match\", False) else 0\n",
    "\n",
    "        # Scriviamo la riga nel CSV\n",
    "        writer.writerow([\n",
    "            company_a, industry_a, country_a, source_a,\n",
    "            company_b, industry_b, country_b, source_b,\n",
    "            label\n",
    "        ])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle metriche di recision Recall e F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie in pairwise: 98726\n",
      "Numero di coppie in ground truth: 159\n",
      "Numero di coppie in ground truth con label a 1: 80\n",
      "Numero di coppie in intersezione: 145\n",
      "Numero di coppie nell'intersezione con label 1: 73\n",
      "Precision: 0.5034\n",
      "Recall: 0.9125\n",
      "F1-Score: 0.6489\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path dei file (aggiorna con i percorsi reali)\n",
    "pairwise_file = 'matched_companies_detailed.csv'\n",
    "groundtruth_file = 'data/ground_truth.csv'\n",
    "\n",
    "# Caricamento dei file\n",
    "pairwise = pd.read_csv(pairwise_file)\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# Funzione di supporto per normalizzare i nomi di società (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# Funzione per ottenere una tupla ordinata, così che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# Creiamo la colonna 'normalized_pair' in entrambi i dataset\n",
    "pairwise['normalized_pair'] = pairwise.apply(\n",
    "    lambda x: normalize_pair(x, 'company_name_left', 'company_name_right'), axis=1\n",
    ")\n",
    "groundtruth['normalized_pair'] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, 'company_a', 'company_b'), axis=1\n",
    ")\n",
    "\n",
    "# Convertiamo in insiemi per confronto\n",
    "pairwise_set = set(pairwise['normalized_pair'])\n",
    "groundtruth_set = set(groundtruth['normalized_pair'])\n",
    "\n",
    "# Intersezione tra le coppie del dataset pairwise e quelle della ground truth (tutte, indipendentemente dalla label)\n",
    "intersection = pairwise_set.intersection(groundtruth_set)\n",
    "\n",
    "# Filtriamo la ground truth per ottenere solo le coppie con label 1 (cioè i match veri)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth['label'] == 1]['normalized_pair'])\n",
    "\n",
    "# Calcoliamo il numero di coppie dell'intersezione che hanno label 1\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# Calcolo delle metriche:\n",
    "# - Precisione: fra le coppie previste (cioè quelle in intersezione), quanti sono corretti (label=1)\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "# - Recall: fra tutte le coppie corrette presenti in ground truth, quanti sono stati trovati\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output dei risultati\n",
    "print(f\"Numero di coppie in pairwise: {len(pairwise_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f'Numero di coppie in ground truth con label a 1: {len(groundtruth_true_set)}')\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie nell'intersezione con label 1: {tp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Blocking e Calcolo delle Metriche dei Risultati del Transformer\n",
    "\n",
    "Il seguente script è utilizzato per calcolare le metriche di precisione, recall e F1-score dei risultati ottenuti dal modello Transformer per il matching delle entità. \n",
    "\n",
    "Questo script permette di valutare l'efficacia del modello Transformer nel riconoscere correttamente le coppie di entità duplicate, fornendo metriche chiave per l'analisi delle performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 9515230\n",
      "Dimensioni della similarity_matrix: (9515230, 3)\n",
      "Numero di coppie finali considerate 'match': 118429\n",
      "✅ Blocking e filtraggio completati! Coppie salvate in `blocked_pairs.tsv`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "#\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "#\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file, low_memory=False)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "\n",
    "# Rimuovi righe con company_name mancante\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 2) Creazione di un blocking “non troppo restrittivo”\n",
    "#\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Blocco per industry\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "\n",
    "# Blocco per city\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))\n",
    "\n",
    "# SortedNeighbourhood su company_name (finestra=5)\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "# Creazione delle coppie candidate\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 3) Definizione delle regole di confronto\n",
    "#\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Similarità Jaro-Winkler sul nome\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "\n",
    "# Check esatto su industry\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "\n",
    "# Check esatto su city\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "\n",
    "#\n",
    "# 4) Calcolo della matrice di similarità\n",
    "#\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 5) Selezione delle coppie “match” (stessa logica del vecchio script)\n",
    "#\n",
    "# Regola:\n",
    "#  - name_sim > 0.80 e < 0.92, OPPURE\n",
    "#  - name_sim > 0.9 e industry_exact == 1 e city_exact == 1\n",
    "#\n",
    "matches = similarity_matrix[\n",
    "    (\n",
    "        (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92)\n",
    "    )\n",
    "    |\n",
    "    (\n",
    "        (similarity_matrix['name_sim'] > 0.9)\n",
    "        & (similarity_matrix['industry_exact'] == 1)\n",
    "        & (similarity_matrix['city_exact'] == 1)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 6) Convertiamo queste coppie in formato TSV per il Transformer\n",
    "#\n",
    "\n",
    "# a) Resettiamo l'indice (MultiIndex -> 'level_0' e 'level_1')\n",
    "matches = matches.reset_index()\n",
    "\n",
    "# b) Creiamo le colonne da esportare\n",
    "matches['sentence1'] = df.loc[matches['level_0'], 'company_name'].values\n",
    "matches['sentence2'] = df.loc[matches['level_1'], 'company_name'].values\n",
    "matches['label'] = \"?\"  # non hai etichette, lasciamo \"?\". Cambia se serve.\n",
    "\n",
    "# Opzionalmente, se vuoi evitare duplicati con company_name identici\n",
    "# matches = matches[matches['sentence1'] != matches['sentence2']]\n",
    "\n",
    "#\n",
    "# 7) Salvataggio in TSV\n",
    "#\n",
    "matches[[\"level_0\", \"sentence1\", \"sentence2\", \"label\"]].to_csv(\n",
    "    \"entity-matching-transformer/blocked_pairs.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    ")\n",
    "\n",
    "print(\"✅ Blocking e filtraggio completati! Coppie salvate in `blocked_pairs.tsv`.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conteggio intersezione blocking con gt\n",
    "\n",
    "Questo script serve per contare le coppie di intersezione tra i risultati del blocking e la ground truth (GT). Utilizza tecniche di normalizzazione dei nomi delle aziende per garantire che le coppie siano confrontate in modo coerente, indipendentemente dall'ordine o dalle variazioni minori nei nomi. L'intersezione risultante fornisce un'indicazione di quante coppie identificate nel blocking sono effettivamente presenti nella ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BLOCKED] Numero di coppie nel file di blocking: 118429\n",
      "[GT] Numero di coppie totali nella ground truth: 159\n",
      "[BLOCKED] Numero di coppie distinte (normalizzate) nel blocking: 98110\n",
      "[GT] Numero di coppie distinte (normalizzate) nella ground truth: 159\n",
      "[INFO] Numero di coppie del blocking che sono nella GT: 145\n",
      "[INFO] Percentuale di coppie di blocking trovate nella GT: 0.15%\n",
      "Esempi di coppie trovate in BOTH (blocking e GT):\n",
      "[('shenzhen minde electronics technology', 'shenzhen mindray biomedical electronics'), ('pzu', 'pzu sa'), ('andhra bank', 'andhra paper'), ('51job', '51job inc'), ('nomura co ltd', 'nomura holdings')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# (1) Lettura delle coppie risultanti dal blocking\n",
    "# ------------------------------------------------\n",
    "df_blocked = pd.read_csv(\n",
    "    \"entity-matching-transformer/blocked_pairs.tsv\", \n",
    "    sep=\"\\t\"\n",
    ")\n",
    "# Supponendo che il tuo TSV abbia queste colonne: [\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    "# Verifica che le colonne coincidano con quelle che hai salvato!\n",
    "\n",
    "print(f\"[BLOCKED] Numero di coppie nel file di blocking: {len(df_blocked)}\")\n",
    "\n",
    "# (2) Lettura della ground truth\n",
    "# ------------------------------------------------\n",
    "df_gt = pd.read_csv(\"data/ground_truth.csv\")\n",
    "\n",
    "print(f\"[GT] Numero di coppie totali nella ground truth: {len(df_gt)}\")\n",
    "\n",
    "\n",
    "# (3) Funzione di normalizzazione dei nomi (opzionale)\n",
    "# ------------------------------------------------\n",
    "def normalize_company_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Esempio semplice di normalizzazione:\n",
    "    - converti in minuscolo\n",
    "    - rimuovi punteggiatura\n",
    "    - fai strip di spazi iniziali/finali\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"  # o gestisci diversamente i NaN\n",
    "    name = name.lower().strip()\n",
    "    # Rimuove caratteri non alfanumerici (tranne spazi)\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    # Rimuove eventuali doppi spazi\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "# (4) Creazione di set di coppie \"normalizzate\" per il blocking\n",
    "# -------------------------------------------------------------\n",
    "# Se vuoi considerare la coppia come NON ordinata (A,B) == (B,A), ordina i nomi:\n",
    "blocked_pairs_set = set()\n",
    "\n",
    "for idx, row in df_blocked.iterrows():\n",
    "    # Normalizza i nomi\n",
    "    c1 = normalize_company_name(row[\"sentence1\"])\n",
    "    c2 = normalize_company_name(row[\"sentence2\"])\n",
    "    # Ordina la tuple, cosi \"A-B\" e \"B-A\" finiscono uguali\n",
    "    pair = tuple(sorted([c1, c2]))\n",
    "    blocked_pairs_set.add(pair)\n",
    "\n",
    "print(f\"[BLOCKED] Numero di coppie distinte (normalizzate) nel blocking: {len(blocked_pairs_set)}\")\n",
    "\n",
    "\n",
    "# (5) Creazione di set di coppie \"normalizzate\" per la ground truth\n",
    "# -----------------------------------------------------------------\n",
    "gt_pairs_set = set()\n",
    "\n",
    "for idx, row in df_gt.iterrows():\n",
    "    # Puoi considerare solo company_a e company_b (se sono i campi che t'interessano per l'allineamento)\n",
    "    c_a = normalize_company_name(row[\"company_a\"])\n",
    "    c_b = normalize_company_name(row[\"company_b\"])\n",
    "    # Anche qui, se vuoi l'ordine non rilevante, fai sorted\n",
    "    pair = tuple(sorted([c_a, c_b]))\n",
    "    gt_pairs_set.add(pair)\n",
    "\n",
    "print(f\"[GT] Numero di coppie distinte (normalizzate) nella ground truth: {len(gt_pairs_set)}\")\n",
    "\n",
    "\n",
    "# (6) Intersezione tra i due insiemi\n",
    "# ----------------------------------\n",
    "intersection_pairs = blocked_pairs_set.intersection(gt_pairs_set)\n",
    "\n",
    "print(f\"[INFO] Numero di coppie del blocking che sono nella GT: {len(intersection_pairs)}\")\n",
    "\n",
    "# Eventualmente, puoi calcolare anche la quota in percentuale\n",
    "perc = (len(intersection_pairs) / len(blocked_pairs_set)) * 100 if len(blocked_pairs_set) else 0\n",
    "print(f\"[INFO] Percentuale di coppie di blocking trovate nella GT: {perc:.2f}%\")\n",
    "\n",
    "# (7) Se vuoi, puoi anche estrarre le righe corrispondenti all’intersezione\n",
    "# in modo da analizzarle:\n",
    "intersection_list = list(intersection_pairs)\n",
    "\n",
    "# *Attenzione*: se vuoi fare un join tabellare più classico, \n",
    "# dovresti creare un DF con \"c1_norm\", \"c2_norm\" e poi fare merge con \n",
    "# un DF analogo per la GT.\n",
    "\n",
    "# Per semplicità, stampiamo solo qualche esempio di coppie in comune\n",
    "print(\"Esempi di coppie trovate in BOTH (blocking e GT):\")\n",
    "print(intersection_list[:5])  # prime 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie predette come match dal modello: 1484\n",
      "Numero di coppie in ground truth: 159\n",
      "Numero di coppie in ground truth con label 1: 80\n",
      "Numero di coppie in intersezione: 14\n",
      "Numero di coppie corrette (True Positives): 11\n",
      "📌 Precision: 0.7857\n",
      "📌 Recall: 0.1375\n",
      "📌 F1-Score: 0.2340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📂 Percorsi dei file (aggiorna con i percorsi reali)\n",
    "model_output_file = \"entity-matching-transformer/predicted_matches.tsv\"  # File generato dal modello\n",
    "groundtruth_file = \"data/ground_truth.csv\"  # Ground truth\n",
    "\n",
    "# 📥 Caricamento dei file\n",
    "model_results = pd.read_csv(model_output_file, sep=\"\\t\")\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# 🔍 Normalizzazione dei nomi di società (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# 📌 Funzione per ottenere una tupla ordinata, così che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# 📊 Filtriamo solo le coppie che il modello ha predetto come match (label 1)\n",
    "model_results = model_results[model_results[\"label\"] == 1]\n",
    "\n",
    "# 🛠 Creiamo la colonna 'normalized_pair' nei dataset\n",
    "model_results[\"normalized_pair\"] = model_results.apply(\n",
    "    lambda x: normalize_pair(x, \"sentence1\", \"sentence2\"), axis=1\n",
    ")\n",
    "groundtruth[\"normalized_pair\"] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, \"company_a\", \"company_b\"), axis=1\n",
    ")\n",
    "\n",
    "# 🔀 Convertiamo in insiemi per confronto\n",
    "model_set = set(model_results[\"normalized_pair\"])\n",
    "groundtruth_set = set(groundtruth[\"normalized_pair\"])\n",
    "\n",
    "# 🔗 Intersezione tra le coppie predette e quelle nella ground truth\n",
    "intersection = model_set.intersection(groundtruth_set)\n",
    "\n",
    "# 🎯 Filtriamo la ground truth per ottenere solo i veri match (label = 1)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth[\"label\"] == 1][\"normalized_pair\"])\n",
    "\n",
    "# ✅ Calcoliamo il numero di True Positives (coppie predette che sono davvero match)\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# 📊 Calcolo delle metriche:\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# 📢 Output dei risultati\n",
    "print(f\"Numero di coppie predette come match dal modello: {len(model_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f\"Numero di coppie in ground truth con label 1: {len(groundtruth_true_set)}\")\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie corrette (True Positives): {tp}\")\n",
    "print(f\"📌 Precision: {precision:.4f}\")\n",
    "print(f\"📌 Recall: {recall:.4f}\")\n",
    "print(f\"📌 F1-Score: {f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
