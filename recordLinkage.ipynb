{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Funzionamento dello Script (Passo dopo Passo)\n",
    "\n",
    "### 1) Caricamento e Pre-elaborazione dei Dati\n",
    "Si parte caricando il file CSV contenente le informazioni aziendali. Dopo aver letto il dataset, vengono selezionate le sole colonne considerate importanti per il matching, in questo caso:\n",
    "\n",
    "- `company_name`\n",
    "- `industry`\n",
    "- `headquarters_city`\n",
    "\n",
    "A questo punto, si eliminano (drop) le righe che non hanno il nome dell‚Äôazienda (`company_name`), perch√© tale colonna √® ritenuta fondamentale per confrontare i record. Infine, si stampa quanti record validi rimangono dopo questa pulizia.\n",
    "\n",
    "**Perch√© si fa:** riduciamo il DataFrame a ci√≤ che serve per identificare la stessa entit√†, eliminando dati mancanti sui campi essenziali.\n",
    "\n",
    "### 2) Creazione di un ‚ÄúBlocking‚Äù non troppo restrittivo\n",
    "Lo script utilizza la libreria `recordlinkage` per definire le regole di blocco (blocking). In particolare, si creano due regole:\n",
    "\n",
    "- **Exact Block su `industry`:**\n",
    "    Raggruppa i record per settore, cos√¨ il confronto avviene solo tra aziende che appartengono allo stesso `industry`.\n",
    "\n",
    "- **SortedNeighbourhood su `company_name` con finestra = 5:**\n",
    "    Ordina le aziende in base al nome e poi confronta ogni azienda con le 5 precedenti e le 5 successive. Lo scopo √® catturare nomi che sono ‚Äúvicini‚Äù a livello alfabetico, evitando di confrontare aziende i cui nomi sarebbero nettamente diversi.\n",
    "\n",
    "Il risultato di queste due regole viene unito (logica OR). Ci√≤ significa che una coppia di record passa alla fase successiva se soddisfa almeno una delle due condizioni di blocco.\n",
    "\n",
    "Alla fine, si stampa quante coppie candidate abbiamo ottenuto: √® il numero di possibili confronti che andranno analizzati pi√π a fondo.\n",
    "\n",
    "**Perch√© si fa:** il blocking √® usato per ridurre il numero di confronti dal potenziale \\(O(n^2)\\) a un insieme pi√π piccolo e verosimile. Si sceglie un blocco ‚Äúnon troppo restrittivo‚Äù cos√¨ da non perdere troppi possibili match.\n",
    "\n",
    "### 3) Definizione delle Regole di Confronto (Compare)\n",
    "Si istanzia un oggetto `Compare()` di `recordlinkage`, in cui definiamo le metriche usate per confrontare le coppie candidate:\n",
    "\n",
    "- **Somiglianza di stringa (Jaro-Winkler) per `company_name`:**\n",
    "    Calcola un punteggio da 0 (completamente diversi) a 1 (identici). Jaro-Winkler √® utile per correggere piccoli errori di battitura o variazioni del nome.\n",
    "\n",
    "- **Exact Match per `industry` e `headquarters_city`:**\n",
    "    Se i due record hanno esattamente lo stesso valore, la metrica vale 1, altrimenti 0.\n",
    "\n",
    "In sostanza, cos√¨ facendo, potremo valutare se i nomi delle aziende sono molto simili, e allo stesso tempo se `industry` e `headquarters_city` coincidono.\n",
    "\n",
    "### 4) Calcolo della Matrice di Similarit√†\n",
    "Viene calcolata la `similarity_matrix` per tutte le coppie candidate prodotte dal blocking. Ogni riga della matrice corrisponde a una coppia \\((record_A, record_B)\\); ogni colonna √® una metrica (es. `name_sim`, `industry_exact`, `city_exact`). Si stampa la dimensione di questa matrice, cio√® quante coppie e quante metriche sono state calcolate.\n",
    "\n",
    "**Perch√© si fa:** per ogni coppia ritenuta potenzialmente ‚Äúsospetta‚Äù (stessa `industry` o nome vicino), si ottengono punteggi che ci aiutano a decidere se la coppia √® davvero la stessa azienda.\n",
    "\n",
    "### 5) Selezione delle Coppie Considerate ‚ÄòMatch‚Äô\n",
    "Dalla matrice di similarit√†, si estraggono solo le righe che soddisfano certe regole:\n",
    "\n",
    "- Nome simile (`name_sim > 0.95`), oppure\n",
    "- Stesso settore e stessa citt√† (`industry_exact == 1` e `city_exact == 1`).\n",
    "\n",
    "Le coppie che rispettano almeno una di queste condizioni vengono prese come ‚Äúmatch‚Äù. Si stampa quante coppie totali soddisfano i criteri.\n",
    "\n",
    "**Perch√© si fa:** abbiamo impostato delle soglie (es. 0.95 su Jaro-Winkler) e regole di abbinamento. A seconda dei dati, si pu√≤ decidere di alzare/abbassare le soglie per ottenere pi√π o meno match.\n",
    "\n",
    "### 6) Recupero dei Valori Originali tramite ‚ÄúJoin‚Äù\n",
    "Dopo aver deciso quali coppie sono ‚Äúmatch‚Äù, si vuole visualizzare i dati originali (il nome, il settore, la citt√† per entrambi i record). Per farlo:\n",
    "\n",
    "- Si resetta l‚Äôindice (che era una `MultiIndex` di coppie) per ottenere due colonne: `id_left` e `id_right`, corrispondenti alle posizioni dei record nel DataFrame originale.\n",
    "- Si fa un merge con `df` usando `id_left` e poi un altro merge con `id_right`. Cos√¨ si recuperano i valori effettivi delle colonne `company_name`, `industry`, `headquarters_city` per entrambi i record della coppia (quelli ‚Äúdi sinistra‚Äù e ‚Äúdi destra‚Äù).\n",
    "\n",
    "Ora nel DataFrame finale troviamo colonne come: `company_name_left`, `company_name_right`, `industry_left`, `industry_right`, e cos√¨ via, affiancate ai punteggi di similarit√†.\n",
    "\n",
    "**Perch√© si fa:** la tabella di similarit√† di base contiene solo i punteggi e gli indici delle coppie. Per controllare ‚Äúa occhio‚Äù se i match hanno senso, serve ricostruire i valori testuali originali.\n",
    "\n",
    "### 7) Salvataggio del Risultato in CSV\n",
    "Infine, si esporta il DataFrame risultante (che contiene le coppie abbinate pi√π le colonne left e right) in un file CSV, in modo da avere un report di tutti i match, con i punteggi di somiglianza e i dati affiancati.\n",
    "\n",
    "**Perch√© si fa:** questo file finale consente di verificare manualmente (o mostrare al professore/ai colleghi) i match individuati, con la prova testuale delle colonne corrispondenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_18428\\695966414.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 7358685\n",
      "Dimensioni della similarity_matrix: (7358685, 3)\n",
      "Numero di coppie finali considerate 'match': 102711\n",
      "‚úÖ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similarit√†\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92) |\n",
    "    (similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che √® una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similarit√†: name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"‚úÖ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avr√† le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e cos√¨ via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convertire ground_truth.json in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\n",
    "        \"company_a\", \"industry_a\", \"country_a\", \"source_a\",\n",
    "        \"company_b\", \"industry_b\", \"country_b\", \"source_b\",\n",
    "        \"label\"\n",
    "    ])\n",
    "\n",
    "    # Per ogni record in data[\"ground_truth\"]\n",
    "    for record in data[\"ground_truth\"]:\n",
    "        pairs = record[\"pairs\"]\n",
    "        # Assumiamo che pairs contenga esattamente 2 elementi:\n",
    "        pair_a, pair_b = pairs[0], pairs[1]\n",
    "\n",
    "        # Estraiamo i valori per la prima azienda\n",
    "        company_a = pair_a.get(\"company-name\", \"\")\n",
    "        industry_a = pair_a.get(\"industry\", \"\")\n",
    "        country_a = pair_a.get(\"country\", \"\")\n",
    "        source_a = pair_a.get(\"source\", \"\")\n",
    "\n",
    "        # Estraiamo i valori per la seconda azienda\n",
    "        company_b = pair_b.get(\"company-name\", \"\")\n",
    "        industry_b = pair_b.get(\"industry\", \"\")\n",
    "        country_b = pair_b.get(\"country\", \"\")\n",
    "        source_b = pair_b.get(\"source\", \"\")\n",
    "\n",
    "        # Se il campo industry √® una lista, uniamo gli elementi in una stringa\n",
    "        if isinstance(industry_a, list):\n",
    "            industry_a = \"; \".join(industry_a)\n",
    "        if isinstance(industry_b, list):\n",
    "            industry_b = \"; \".join(industry_b)\n",
    "\n",
    "        # Convertiamo eventuali None in stringhe vuote\n",
    "        country_a = country_a or \"\"\n",
    "        country_b = country_b or \"\"\n",
    "        industry_a = industry_a or \"\"\n",
    "        industry_b = industry_b or \"\"\n",
    "\n",
    "        # Impostiamo la label: 1 se match √® true, 0 se false\n",
    "        label = 1 if record.get(\"match\", False) else 0\n",
    "\n",
    "        # Scriviamo la riga nel CSV\n",
    "        writer.writerow([\n",
    "            company_a, industry_a, country_a, source_a,\n",
    "            company_b, industry_b, country_b, source_b,\n",
    "            label\n",
    "        ])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle metriche di recision Recall e F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie in pairwise: 83779\n",
      "Numero di coppie in ground truth: 211\n",
      "Numero di coppie in ground truth con label a 1: 75\n",
      "Numero di coppie in intersezione: 202\n",
      "Numero di coppie nell'intersezione con label 1: 73\n",
      "Precision: 0.3614\n",
      "Recall: 0.9733\n",
      "F1-Score: 0.5271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path dei file (aggiorna con i percorsi reali)\n",
    "pairwise_file = 'matched_companies_detailed.csv'\n",
    "groundtruth_file = 'data/ground_truth.csv'\n",
    "\n",
    "# Caricamento dei file\n",
    "pairwise = pd.read_csv(pairwise_file)\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# Funzione di supporto per normalizzare i nomi di societ√† (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# Funzione per ottenere una tupla ordinata, cos√¨ che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# Creiamo la colonna 'normalized_pair' in entrambi i dataset\n",
    "pairwise['normalized_pair'] = pairwise.apply(\n",
    "    lambda x: normalize_pair(x, 'company_name_left', 'company_name_right'), axis=1\n",
    ")\n",
    "groundtruth['normalized_pair'] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, 'company_a', 'company_b'), axis=1\n",
    ")\n",
    "\n",
    "# Convertiamo in insiemi per confronto\n",
    "pairwise_set = set(pairwise['normalized_pair'])\n",
    "groundtruth_set = set(groundtruth['normalized_pair'])\n",
    "\n",
    "# Intersezione tra le coppie del dataset pairwise e quelle della ground truth (tutte, indipendentemente dalla label)\n",
    "intersection = pairwise_set.intersection(groundtruth_set)\n",
    "\n",
    "# Filtriamo la ground truth per ottenere solo le coppie con label 1 (cio√® i match veri)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth['label'] == 1]['normalized_pair'])\n",
    "\n",
    "# Calcoliamo il numero di coppie dell'intersezione che hanno label 1\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# Calcolo delle metriche:\n",
    "# - Precisione: fra le coppie previste (cio√® quelle in intersezione), quanti sono corretti (label=1)\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "# - Recall: fra tutte le coppie corrette presenti in ground truth, quanti sono stati trovati\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output dei risultati\n",
    "print(f\"Numero di coppie in pairwise: {len(pairwise_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f'Numero di coppie in ground truth con label a 1: {len(groundtruth_true_set)}')\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie nell'intersezione con label 1: {tp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
