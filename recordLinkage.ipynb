{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Obiettivo:\n",
    "✔️ Capire la struttura dei dati  \n",
    "✔️ Adattare il codice per il record linkage in base al nostro schema  \n",
    "\n",
    "### 📌 Analisi dello Schema Mediato (final_mediated_schema.csv)\n",
    "Il dataset contiene informazioni su aziende, con un totale di 22 colonne. Alcune delle più rilevanti per il record linkage sono:\n",
    "\n",
    "| Colonna              | Descrizione                                                                 |\n",
    "|----------------------|-----------------------------------------------------------------------------|\n",
    "| company_name         | Nome dell'azienda (🔑 molto importante per il matching)                    \n",
    "| industry             | Settore dell'azienda                                                        \n",
    "| headquarters_city    | Città della sede (🔑 può essere usata per il blocking)                     \n",
    "| headquarters_country | Paese della sede                                                            \n",
    "| year_founded         | Anno di fondazione (🔑 potrebbe essere usato per similarità numerica)       \n",
    "| ownership            | Tipo di proprietà (Public, Private, ecc.)                                   \n",
    "| company_number       | Numero identificativo (se presente, è un match perfetto)                    \n",
    "| employee_count       | Numero di dipendenti (🔑 buono per similarità numerica)                     \n",
    "| market_cap_usd       | Capitalizzazione di mercato                                                 \n",
    "| company_website      | Sito web (🔑 se presente, può essere un forte indicatore di match)         \n",
    "| social_media_links   | Link ai social media                                                        \n",
    "| representative_name  | Nome del rappresentante (può aiutare nel matching)                          \n",
    "| _source_table        | Fonte del dato (utile per sapere da dove provengono i dati).                \n",
    "\n",
    "### 📌 Funzionamento dello script\n",
    "Lo script implementa un Record Linkage Pipeline, ovvero un processo per trovare e abbinare aziende simili all'interno di un dataset.\n",
    "\n",
    "💡 **Obiettivo:** Identificare duplicati o entità corrispondenti tra i record aziendali.\n",
    "\n",
    "#### 🔹 Step 1: Caricamento e Pulizia del Dataset\n",
    "- Carica il dataset CSV `final_mediated_schema.csv`.\n",
    "- Seleziona solo le colonne utili (`company_name`, `industry`, `headquarters_city`, `year_founded`, ecc.).\n",
    "- Rimuove le righe senza `company_name`, perché il nome dell'azienda è essenziale per il confronto.\n",
    "- Converte `year_founded` e `employee_count` in numeri, evitando errori durante il matching.\n",
    "\n",
    "#### 🔹 Step 2: Blocking per Ridurre i Confronti\n",
    "Il blocking è una tecnica per ridurre il numero di confronti inutili tra le aziende. Lo script utilizza tre strategie di blocking:\n",
    "- **Blocking su `headquarters_city` e `industry`** → Considera solo aziende con la stessa sede e settore.\n",
    "- **Sorted Neighbourhood su `company_name`** → Confronta aziende con nomi simili entro una finestra di 5 righe.\n",
    "- **Blocking su `ownership`** → Confronta solo aziende con la stessa tipologia di proprietà.\n",
    "\n",
    "💡 **Risultato:** Il numero di confronti si riduce da milioni a un sottoinsieme più piccolo di `candidate_pairs`.\n",
    "\n",
    "#### 🔹 Step 3: Pairwise Matching (Confronto tra Coppie)\n",
    "Una volta ottenute le coppie candidate, lo script calcola quanto sono simili usando diverse metriche:\n",
    "\n",
    "| Campo           | Metodo       | Descrizione                                                                 |\n",
    "|-----------------|--------------|-----------------------------------------------------------------------------|\n",
    "| `company_name`  | Jaro-Winkler | Confronta i nomi in base alla distanza tra i caratteri (similitudine testuale). |\n",
    "| `company_website` | Exact Match  | Controlla se i siti web delle aziende coincidono esattamente.                |\n",
    "| `year_founded`  | Gaussiano    | Permette piccole variazioni nell'anno di fondazione.                         |\n",
    "| `employee_count`| Gaussiano    | Permette variazioni nel numero di dipendenti, considerando una distribuzione statistica. |\n",
    "\n",
    "💡 **Risultato:** Viene creata una matrice di similarità tra i record aziendali.\n",
    "\n",
    "#### 🔹 Step 4: Filtraggio delle Migliori Corrispondenze\n",
    "Lo script seleziona le migliori corrispondenze utilizzando una soglia di similarità: ✅ Le aziende sono considerate matching se:\n",
    "- `company_name` ha una somiglianza > 85% (Jaro-Winkler).\n",
    "- `company_website` è esattamente uguale.\n",
    "- `year_founded` e `employee_count` hanno una similitudine combinata > 80%.\n",
    "\n",
    "💡 **Risultato:** Si ottiene un sottoinsieme di aziende che probabilmente rappresentano la stessa entità.\n",
    "\n",
    "#### 🔹 Step 5: Salvataggio dei Risultati\n",
    "Infine, lo script:\n",
    "- Salva le corrispondenze trovate in un file CSV: `matched_companies.csv`\n",
    "- Mostra il numero di aziende abbinate.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_36996\\2829431938.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_founded      55642\n",
      "employee_count    64309\n",
      "dtype: int64\n",
      "🔍 Generato 21304659 confronti dopo il blocking.\n",
      "✅ Matching completato! Salvato in 'matched_companies.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 📂 Caricare il dataset con lo schema mediato\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"  # Modifica con il percorso corretto\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# 🔎 Selezioniamo solo le colonne utili per il matching\n",
    "df = df[['company_name', 'industry', 'headquarters_city', 'year_founded', \n",
    "         'ownership', 'company_number', 'employee_count', 'company_website']]\n",
    "\n",
    "# 📌 Rimuoviamo righe con `company_name` mancante\n",
    "df = df.dropna(subset=['company_name'])\n",
    "\n",
    "# ✅ Convertiamo i numeri nel formato corretto\n",
    "df['year_founded'] = pd.to_numeric(df['year_founded'], errors='coerce')\n",
    "df['employee_count'] = pd.to_numeric(df['employee_count'], errors='coerce')\n",
    "\n",
    "# 🔎 Controlliamo i NaN\n",
    "print(df[['year_founded', 'employee_count']].isna().sum())\n",
    "\n",
    "# ✅ STEP 1: Blocking per ridurre il numero di confronti\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# 🔹 **Blocking 1: Exact Matching su `headquarters_city` e `industry`**\n",
    "indexer.add(recordlinkage.index.Block(['headquarters_city', 'industry']))\n",
    "\n",
    "# 🔹 **Blocking 2: Sorted Neighbourhood su `company_name` con finestra 5**\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "# 🔹 **Blocking 3: Exact Matching su `ownership`**\n",
    "indexer.add(recordlinkage.index.Block(['ownership']))\n",
    "\n",
    "# Creiamo le coppie candidate\n",
    "candidate_pairs = indexer.index(df)\n",
    "\n",
    "print(f\"🔍 Generato {len(candidate_pairs)} confronti dopo il blocking.\")\n",
    "\n",
    "# ✅ STEP 2: Pairwise Matching (Similarità tra i record)\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# 📌 Matching su `company_name` con Jaro-Winkler (string similarity)\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "\n",
    "# 📌 Matching su `company_website` (valore esatto, se presente)\n",
    "compare.exact('company_website', 'company_website', label='website_exact')\n",
    "\n",
    "# 📌 Matching su `year_founded` con tolleranza numerica (metodo Gaussiano)\n",
    "compare.numeric('year_founded', 'year_founded', method='gauss', scale=5, label='year_sim')\n",
    "\n",
    "# 📌 Matching su `employee_count` con metodo \"gauss\"\n",
    "compare.numeric('employee_count', 'employee_count', method='gauss', scale=5, label='employees_sim')  # 🔹 Prova anche step\n",
    "\n",
    "# ✅ STEP 3: Creazione della matrice di similarità tra i record\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "\n",
    "# ✅ STEP 4: Filtraggio delle migliori corrispondenze\n",
    "# Usiamo una soglia: match con almeno 2 metriche alte\n",
    "matches = similarity_matrix[(similarity_matrix['name_sim'] > 0.85) | \n",
    "                            (similarity_matrix['website_exact'] == 1) | \n",
    "                            ((similarity_matrix['year_sim'] > 0.8) & (similarity_matrix['employees_sim'] > 0.8))]\n",
    "\n",
    "# ✅ STEP 5: Salviamo i risultati\n",
    "matches.to_csv(\"matched_companies.csv\")\n",
    "print(f\"✅ Matching completato! Salvato in 'matched_companies.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 Passaggio 1: Convertire ground_truth.json in CSV\n",
    "\n",
    "Attualmente il file JSON ha questa struttura:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"ground_truth\": [\n",
    "        {\n",
    "            \"1&1\": \"companiesMarketCap_dataset\",\n",
    "            \"1&1 AG\": \"disfold-com\"\n",
    "        },\n",
    "        {\n",
    "            \"AMPLUS\": \"ft-com\",\n",
    "            \"AMPLUS SOLAR\": \"AmbitionBox\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Dobbiamo convertirlo in un formato compatibile con il CSV che abbiamo creato. Un buon formato potrebbe essere:\n",
    "\n",
    "```csv\n",
    "company_a,source_a,company_b,source_b\n",
    "1&1,companiesMarketCap_dataset,1&1 AG,disfold-com\n",
    "AMPLUS,ft-com,AMPLUS SOLAR,AmbitionBox\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparare i Dati per Ditto\n",
    "\n",
    "Ditto richiede un dataset in formato TSV con questa struttura:\n",
    "\n",
    "```\n",
    "sentence_1 \\t sentence_2 \\t label\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```\n",
    "1&1 è una società di telecomunicazioni. \\t 1&1 AG è un operatore tedesco di telecomunicazioni. \\t 1\n",
    "AMPLUS è una società di energia. \\t AMPLUS SOLAR è una società di energia rinnovabile. \\t 0\n",
    "```\n",
    "\n",
    "📌 Script per convertire `ground_truth.csv` e `matched_companies.csv` in TSV per Ditto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne in matched_companies: ['Unnamed: 0', 'Unnamed: 1', 'name_sim', 'website_exact', 'year_sim', 'employees_sim']\n",
      "Colonne in final_mediated_schema: ['company_name', 'industry', 'headquarters_address', 'headquarters_city', 'headquarters_country', 'year_founded', 'ownership', 'company_number', 'employee_count', 'market_cap_usd', 'total_revenue_usd', 'net_profit_usd', 'total_assets_usd', 'company_website', 'social_media_links', 'representative_name', 'total_raised', 'company_description', 'company_stage', 'share_price', 'legal_form', '_source_table']\n",
      "✅ File TSV preparati per Ditto!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📂 Carichiamo i dati originali e la ground truth\n",
    "df_gt = pd.read_csv(\"data/ground_truth.csv\")  # Ground-Truth\n",
    "df_matched = pd.read_csv(\"matched_companies.csv\")  # RecordLinkage\n",
    "df_original = pd.read_csv(\"main_outputs/final_mediated_schema.csv\")  # Dataset originale\n",
    "\n",
    "# 🔍 Controlliamo gli indici originali\n",
    "print(\"Colonne in matched_companies:\", df_matched.columns.tolist())\n",
    "print(\"Colonne in final_mediated_schema:\", df_original.columns.tolist())\n",
    "\n",
    "# 🛠 Ricolleghiamo gli indici di matched_companies.csv ai nomi reali delle aziende\n",
    "df_matched = df_matched.rename(columns={'Unnamed: 0': 'index_1', 'Unnamed: 1': 'index_2'})\n",
    "\n",
    "# Convertiamo gli indici a numeri interi\n",
    "df_matched[['index_1', 'index_2']] = df_matched[['index_1', 'index_2']].astype(int)\n",
    "\n",
    "# Facciamo il merge per recuperare i nomi reali delle aziende\n",
    "df_matched = df_matched.merge(df_original[['company_name', 'industry', 'employee_count']], \n",
    "                              left_on='index_1', right_index=True, how='left')\n",
    "df_matched = df_matched.merge(df_original[['company_name']], \n",
    "                              left_on='index_2', right_index=True, how='left', suffixes=('_1', '_2'))\n",
    "\n",
    "# 📌 Prepara il dataset per Ditto (Ground-Truth)\n",
    "gt_pairs = []\n",
    "for _, row in df_gt.iterrows():\n",
    "    sentence_1 = f\"{row['company_a']} è una società con sede in {row['source_a']}.\"\n",
    "    sentence_2 = f\"{row['company_b']} è una società con sede in {row['source_b']}.\"\n",
    "    gt_pairs.append(f\"{sentence_1}\\t{sentence_2}\\t1\")\n",
    "\n",
    "# 📌 Prepara il dataset per Ditto (RecordLinkage Matches)\n",
    "rl_pairs = []\n",
    "for _, row in df_matched.iterrows():\n",
    "    sentence_1 = f\"{row['company_name_1']} è un'azienda in {row['industry']}.\"\n",
    "    sentence_2 = f\"{row['company_name_2']} è un'azienda con {row['employee_count']} dipendenti.\"\n",
    "    rl_pairs.append(f\"{sentence_1}\\t{sentence_2}\\t0\")\n",
    "\n",
    "# 📝 Salviamo i file in formato TSV con UTF-8 per evitare errori di encoding\n",
    "with open(\"ditto/data/ditto_train.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(gt_pairs))\n",
    "\n",
    "with open(\"ditto/data/ditto_test.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(rl_pairs))\n",
    "\n",
    "print(\"✅ File TSV preparati per Ditto!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0+cu111\n",
      "Transformers version: 4.9.2\n",
      "spaCy version: 3.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import spacy\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"spaCy version:\", spacy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Step 2: Installare e Configurare Ditto\n",
    "\n",
    "Esegui questi comandi per installare Ditto:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/megagonlabs/ditto.git\n",
    "cd ditto\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## 🔹 Step 3: Addestrare Ditto\n",
    "\n",
    "Ditto utilizza modelli Transformer (BERT, RoBERTa). Esegui questo script per addestrarlo sulla Ground-Truth:\n",
    "\n",
    "```bash\n",
    "python train_ditto.py \\\n",
    "    --task custom \\\n",
    "    --trainset data/ditto_train.tsv \\\n",
    "    --devset data/ditto_train.tsv \\\n",
    "    --batch_size 16 \\\n",
    "    --max_len 64 \\\n",
    "    --epochs 5 \\\n",
    "    --lr 3e-5 \\\n",
    "    --save_model data/ditto_model.pt\n",
    "```\n",
    "\n",
    "🔹 **Risultato:** Modello salvato in `data/ditto_model.pt`.\n",
    "\n",
    "## 🔹 Step 4: Applicare Ditto al Pairwise Matching\n",
    "\n",
    "Ora che abbiamo addestrato Ditto, usiamo il modello per fare previsioni sui nostri dati:\n",
    "\n",
    "```bash\n",
    "python predict_ditto.py \\\n",
    "    --task custom \\\n",
    "    --testset data/ditto_test.tsv \\\n",
    "    --model data/ditto_model.pt \\\n",
    "    --output data/ditto_results.tsv\n",
    "```\n",
    "\n",
    "🔹 **Risultato:** Previsioni salvate in `data/ditto_results.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confrontare i Risultati tra RecordLinkage e Ditto\n",
    "\n",
    "Ora confrontiamo le prestazioni di RecordLinkage vs Ditto.\n",
    "\n",
    "📌 Script per calcolare precision, recall e F1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# 📂 Carichiamo i risultati\n",
    "df_rl = pd.read_csv(\"matched_companies.csv\")  # RecordLinkage\n",
    "df_ditto = pd.read_csv(\"data/ditto_results.tsv\", sep=\"\\t\", header=None, names=[\"sentence_1\", \"sentence_2\", \"label\"])\n",
    "df_gt = pd.read_csv(\"data/ground_truth.csv\")  # Ground-Truth\n",
    "\n",
    "# 🔄 Convertiamo in set per il confronto\n",
    "set_rl = set(df_rl[\"company_name\"])\n",
    "set_ditto = set(df_ditto[df_ditto[\"label\"] == 1][\"sentence_1\"])\n",
    "set_gt = set(df_gt[\"company_a\"])\n",
    "\n",
    "# 📊 Calcoliamo Precision, Recall e F1-score\n",
    "precision_rl, recall_rl, f1_rl, _ = precision_recall_fscore_support(\n",
    "    [1 if x in set_gt else 0 for x in set_rl],\n",
    "    [1 for _ in set_rl], average='binary')\n",
    "\n",
    "precision_ditto, recall_ditto, f1_ditto, _ = precision_recall_fscore_support(\n",
    "    [1 if x in set_gt else 0 for x in set_ditto],\n",
    "    [1 for _ in set_ditto], average='binary')\n",
    "\n",
    "# 📌 Creiamo il report\n",
    "comparison = pd.DataFrame({\n",
    "    \"Metodo\": [\"RecordLinkage\", \"Ditto\"],\n",
    "    \"Precision\": [precision_rl, precision_ditto],\n",
    "    \"Recall\": [recall_rl, recall_ditto],\n",
    "    \"F1-Score\": [f1_rl, f1_ditto]\n",
    "})\n",
    "\n",
    "# 📝 Salviamo il confronto\n",
    "comparison.to_csv(\"comparison_report.csv\", index=False)\n",
    "print(\"✅ Confronto completato! Salvato in 'comparison_report.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDitto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
