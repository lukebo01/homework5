{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Funzionamento dello Script (Passo dopo Passo)\n",
    "\n",
    "### 1) Caricamento e Pre-elaborazione dei Dati\n",
    "Si parte caricando il file CSV contenente le informazioni aziendali. Dopo aver letto il dataset, vengono selezionate le sole colonne considerate importanti per il matching, in questo caso:\n",
    "\n",
    "- `company_name`\n",
    "- `industry`\n",
    "- `headquarters_city`\n",
    "\n",
    "A questo punto, si eliminano (drop) le righe che non hanno il nome dell‚Äôazienda (`company_name`), perch√© tale colonna √® ritenuta fondamentale per confrontare i record. Infine, si stampa quanti record validi rimangono dopo questa pulizia.\n",
    "\n",
    "**Perch√© si fa:** riduciamo il DataFrame a ci√≤ che serve per identificare la stessa entit√†, eliminando dati mancanti sui campi essenziali.\n",
    "\n",
    "### 2) Creazione di un ‚ÄúBlocking‚Äù non troppo restrittivo\n",
    "Lo script utilizza la libreria `recordlinkage` per definire le regole di blocco (blocking). In particolare, si creano due regole:\n",
    "\n",
    "- **Exact Block su `industry`:**\n",
    "    Raggruppa i record per settore, cos√¨ il confronto avviene solo tra aziende che appartengono allo stesso `industry`.\n",
    "\n",
    "- **SortedNeighbourhood su `company_name` con finestra = 5:**\n",
    "    Ordina le aziende in base al nome e poi confronta ogni azienda con le 5 precedenti e le 5 successive. Lo scopo √® catturare nomi che sono ‚Äúvicini‚Äù a livello alfabetico, evitando di confrontare aziende i cui nomi sarebbero nettamente diversi.\n",
    "\n",
    "Il risultato di queste due regole viene unito (logica OR). Ci√≤ significa che una coppia di record passa alla fase successiva se soddisfa almeno una delle due condizioni di blocco.\n",
    "\n",
    "Alla fine, si stampa quante coppie candidate abbiamo ottenuto: √® il numero di possibili confronti che andranno analizzati pi√π a fondo.\n",
    "\n",
    "**Perch√© si fa:** il blocking √® usato per ridurre il numero di confronti dal potenziale \\(O(n^2)\\) a un insieme pi√π piccolo e verosimile. Si sceglie un blocco ‚Äúnon troppo restrittivo‚Äù cos√¨ da non perdere troppi possibili match.\n",
    "\n",
    "### 3) Definizione delle Regole di Confronto (Compare)\n",
    "Si istanzia un oggetto `Compare()` di `recordlinkage`, in cui definiamo le metriche usate per confrontare le coppie candidate:\n",
    "\n",
    "- **Somiglianza di stringa (Jaro-Winkler) per `company_name`:**\n",
    "    Calcola un punteggio da 0 (completamente diversi) a 1 (identici). Jaro-Winkler √® utile per correggere piccoli errori di battitura o variazioni del nome.\n",
    "\n",
    "- **Exact Match per `industry` e `headquarters_city`:**\n",
    "    Se i due record hanno esattamente lo stesso valore, la metrica vale 1, altrimenti 0.\n",
    "\n",
    "In sostanza, cos√¨ facendo, potremo valutare se i nomi delle aziende sono molto simili, e allo stesso tempo se `industry` e `headquarters_city` coincidono.\n",
    "\n",
    "### 4) Calcolo della Matrice di Similarit√†\n",
    "Viene calcolata la `similarity_matrix` per tutte le coppie candidate prodotte dal blocking. Ogni riga della matrice corrisponde a una coppia \\((record_A, record_B)\\); ogni colonna √® una metrica (es. `name_sim`, `industry_exact`, `city_exact`). Si stampa la dimensione di questa matrice, cio√® quante coppie e quante metriche sono state calcolate.\n",
    "\n",
    "**Perch√© si fa:** per ogni coppia ritenuta potenzialmente ‚Äúsospetta‚Äù (stessa `industry` o nome vicino), si ottengono punteggi che ci aiutano a decidere se la coppia √® davvero la stessa azienda.\n",
    "\n",
    "### 5) Selezione delle Coppie Considerate ‚ÄòMatch‚Äô\n",
    "Dalla matrice di similarit√†, si estraggono solo le righe che soddisfano certe regole:\n",
    "\n",
    "- Nome simile (`name_sim > 0.95`), oppure\n",
    "- Stesso settore e stessa citt√† (`industry_exact == 1` e `city_exact == 1`).\n",
    "\n",
    "Le coppie che rispettano almeno una di queste condizioni vengono prese come ‚Äúmatch‚Äù. Si stampa quante coppie totali soddisfano i criteri.\n",
    "\n",
    "**Perch√© si fa:** abbiamo impostato delle soglie (es. 0.95 su Jaro-Winkler) e regole di abbinamento. A seconda dei dati, si pu√≤ decidere di alzare/abbassare le soglie per ottenere pi√π o meno match.\n",
    "\n",
    "### 6) Recupero dei Valori Originali tramite ‚ÄúJoin‚Äù\n",
    "Dopo aver deciso quali coppie sono ‚Äúmatch‚Äù, si vuole visualizzare i dati originali (il nome, il settore, la citt√† per entrambi i record). Per farlo:\n",
    "\n",
    "- Si resetta l‚Äôindice (che era una `MultiIndex` di coppie) per ottenere due colonne: `id_left` e `id_right`, corrispondenti alle posizioni dei record nel DataFrame originale.\n",
    "- Si fa un merge con `df` usando `id_left` e poi un altro merge con `id_right`. Cos√¨ si recuperano i valori effettivi delle colonne `company_name`, `industry`, `headquarters_city` per entrambi i record della coppia (quelli ‚Äúdi sinistra‚Äù e ‚Äúdi destra‚Äù).\n",
    "\n",
    "Ora nel DataFrame finale troviamo colonne come: `company_name_left`, `company_name_right`, `industry_left`, `industry_right`, e cos√¨ via, affiancate ai punteggi di similarit√†.\n",
    "\n",
    "**Perch√© si fa:** la tabella di similarit√† di base contiene solo i punteggi e gli indici delle coppie. Per controllare ‚Äúa occhio‚Äù se i match hanno senso, serve ricostruire i valori testuali originali.\n",
    "\n",
    "### 7) Salvataggio del Risultato in CSV\n",
    "Infine, si esporta il DataFrame risultante (che contiene le coppie abbinate pi√π le colonne left e right) in un file CSV, in modo da avere un report di tutti i match, con i punteggi di somiglianza e i dati affiancati.\n",
    "\n",
    "**Perch√© si fa:** questo file finale consente di verificare manualmente (o mostrare al professore/ai colleghi) i match individuati, con la prova testuale delle colonne corrispondenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_21184\\3244916458.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 7358685\n",
      "Dimensioni della similarity_matrix: (7358685, 3)\n",
      "Numero di coppie finali considerate 'match': 112043\n",
      "‚úÖ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similarit√†\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.8) &  (similarity_matrix['name_sim'] < 0.95) |\n",
    "    ((similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1))\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che √® una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similarit√†: name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"‚úÖ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avr√† le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e cos√¨ via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Script completo che esegue il campionamento del CSV `matched_companies_detailed.csv` seguendo i criteri indicati\n",
    "\n",
    "### Passaggi:\n",
    "\n",
    "1. Filtra le coppie con similarit√† (`name_sim`) tra 0.6 e 0.7 (o intervallo che preferisci).\n",
    "2. Opzionalmente filtra per diversit√† (ad es. `industry_left` != `industry_right` o altre condizioni).\n",
    "3. Applica un campionamento sistematico per ottenere esattamente 2000 coppie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campionamento completato: 1000 righe salvate in 'matched_companies_sampled.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Leggi il CSV originale\n",
    "df = pd.read_csv(\"matched_companies_detailed.csv\")\n",
    "\n",
    "# Normalizza i nomi delle aziende\n",
    "df[\"company_name_left\"] = df[\"company_name_left\"].str.strip().str.lower()\n",
    "df[\"company_name_right\"] = df[\"company_name_right\"].str.strip().str.lower()\n",
    "\n",
    "# Funzione di similarit√†\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Calcoliamo la similarit√† su ogni riga\n",
    "df[\"name_similarity\"] = df.apply(lambda row: similar(row[\"company_name_left\"], row[\"company_name_right\"]), axis=1)\n",
    "\n",
    "# Filtra per similarit√† (tra 0.6 e 0.7 come nella ground truth)\n",
    "filtered_df = df[(df[\"name_similarity\"] >= 0.6) & (df[\"name_similarity\"] <= 0.7)]\n",
    "\n",
    "# Conta le righe rimaste\n",
    "num_rows = len(filtered_df)\n",
    "\n",
    "# Calcola il passo per ottenere ~2000 righe\n",
    "step = max(1, num_rows // 1000)\n",
    "\n",
    "# Campionamento sistematico ogni 'step' righe\n",
    "sampled_df = filtered_df.iloc[::step]\n",
    "\n",
    "# Seleziona solo le prime 2000 righe\n",
    "sampled_df = sampled_df.head(1000)\n",
    "\n",
    "# Salva il CSV campionato\n",
    "sampled_df.to_csv(\"matched_companies_sampled.csv\", index=False)\n",
    "\n",
    "print(f\"Campionamento completato: {len(sampled_df)} righe salvate in 'matched_companies_sampled.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Passaggio 1: Convertire ground_truth.json in CSV\n",
    "\n",
    "Attualmente il file JSON ha questa struttura:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"ground_truth\": [\n",
    "        {\n",
    "            \"1&1\": \"companiesMarketCap_dataset\",\n",
    "            \"1&1 AG\": \"disfold-com\"\n",
    "        },\n",
    "        {\n",
    "            \"AMPLUS\": \"ft-com\",\n",
    "            \"AMPLUS SOLAR\": \"AmbitionBox\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Dobbiamo convertirlo in un formato compatibile con il CSV che abbiamo creato. Un buon formato potrebbe essere:\n",
    "\n",
    "```csv\n",
    "company_a,source_a,company_b,source_b\n",
    "1&1,companiesMarketCap_dataset,1&1 AG,disfold-com\n",
    "AMPLUS,ft-com,AMPLUS SOLAR,AmbitionBox\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# data[\"ground_truth\"] contiene una lista di oggetti\n",
    "# Ognuno di questi oggetti ha esattamente 2 coppie \"nome\": \"fonte\", es:\n",
    "# {\n",
    "#   \"1&1\": \"companiesMarketCap_dataset\",\n",
    "#   \"1&1 AG\": \"disfold-com\"\n",
    "# }\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\"company_a\", \"source_a\", \"company_b\", \"source_b\"])\n",
    "\n",
    "    # Per ogni oggetto in data[\"ground_truth\"], estraiamo i 2 pair\n",
    "    for pair_dict in data[\"ground_truth\"]:\n",
    "        # pair_dict √® un dizionario, es: {\"1&1\": \"companiesMarketCap_dataset\", \"1&1 AG\": \"disfold-com\"}\n",
    "        items = list(pair_dict.items())  # Convertiamo in lista di tuple [(company, source), (company, source)]\n",
    "        \n",
    "        # Assumiamo che ci siano esattamente 2 coppie\n",
    "        (company_a, source_a) = items[0]\n",
    "        (company_b, source_b) = items[1]\n",
    "\n",
    "        # Scriviamo una riga nel CSV\n",
    "        writer.writerow([company_a, source_a, company_b, source_b])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "---\n",
    "\n",
    "## üìä Valutazione dei Risultati Ottenuti\n",
    "\n",
    "In questa sezione, analizzeremo i risultati ottenuti dal processo di matching delle aziende. Valuteremo l'accuratezza e la qualit√† dei match identificati, confrontandoli con il ground truth disponibile.\n",
    "\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RISULTATI RECORD LINKAGE (names, MultiIndex) ===\n",
      "Precision: 0.012\n",
      "Recall:    0.059\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recordlinkage.measures import precision, recall, fscore\n",
    "\n",
    "# Ground truth\n",
    "gt_df = pd.read_csv(\"data/ground_truth.csv\")\n",
    "gt_df[\"company_a\"] = gt_df[\"company_a\"].str.strip().str.lower()\n",
    "gt_df[\"company_b\"] = gt_df[\"company_b\"].str.strip().str.lower()\n",
    "\n",
    "true_pairs = {\n",
    "    tuple(sorted([row[\"company_a\"], row[\"company_b\"]]))\n",
    "    for _, row in gt_df.iterrows()\n",
    "}\n",
    "# Convertiamo in MultiIndex\n",
    "true_links = pd.MultiIndex.from_tuples(true_pairs, names=[\"company_left\", \"company_right\"])\n",
    "\n",
    "# Predetti\n",
    "pred_df = pd.read_csv(\"matched_companies_sampled.csv\")\n",
    "pred_df[\"company_name_left\"] = pred_df[\"company_name_left\"].str.strip().str.lower()\n",
    "pred_df[\"company_name_right\"] = pred_df[\"company_name_right\"].str.strip().str.lower()\n",
    "\n",
    "pred_pairs = {\n",
    "    tuple(sorted([row[\"company_name_left\"], row[\"company_name_right\"]]))\n",
    "    for _, row in pred_df.iterrows()\n",
    "}\n",
    "# Convertiamo in MultiIndex\n",
    "pred_links = pd.MultiIndex.from_tuples(pred_pairs, names=[\"company_left\", \"company_right\"])\n",
    "\n",
    "# Calcolo metriche\n",
    "p = precision(true_links, pred_links)\n",
    "r = recall(true_links, pred_links)\n",
    "\n",
    "print(\"=== RISULTATI RECORD LINKAGE (names, MultiIndex) ===\")\n",
    "print(f\"Precision: {p:.3f}\")\n",
    "print(f\"Recall:    {r:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
