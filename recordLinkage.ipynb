{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Riduzione dello Spazio di Confronto (Blocking e Sorted Neighbourhood)\n",
    "\n",
    "Per evitare confronti massivi tra ogni record (un‚Äôoperazione computazionalmente onerosa), si applicano tecniche per restringere lo spazio di confronto. In questo approccio vengono utilizzate strategie in serie:\n",
    "\n",
    "### Blocking per Settore e per Citt√†\n",
    "- **Descrizione:**  \n",
    "  I record vengono raggruppati in blocchi in base a valori condivisi.\n",
    "  - **Settore:** Le aziende vengono suddivise per settore industriale, poich√© quelle dello stesso settore hanno maggiori probabilit√† di essere simili.\n",
    "  - **Citt√†:** Si applica un ulteriore livello di blocking basato sulla citt√†, restringendo il confronto ai record geograficamente vicini.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Immagina un dataset con aziende nei settori \"Tecnologia\", \"Sanit√†\" e \"Finanza\", localizzate in citt√† come \"Milano\", \"Roma\" e \"Torino\". Verranno confrontate solo le aziende che appartengono allo stesso settore **e** alla stessa citt√†.\n",
    "\n",
    "### Sorted Neighbourhood\n",
    "- **Descrizione:**  \n",
    "  Dopo aver applicato il blocking, i record vengono ordinati in base al nome dell‚Äôazienda. Solo i record vicini, all‚Äôinterno di una finestra mobile (ad esempio, 5 record consecutivi), vengono confrontati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Considera una lista ordinata alfabeticamente:\n",
    "  - `AlphaTech`\n",
    "  - `Alphatech Solutions`\n",
    "  - `Beta Corp`\n",
    "  - `Gamma Inc`\n",
    "  \n",
    "  Solo \"AlphaTech\" e \"Alphatech Solutions\" verranno confrontati, evidenziando possibili duplicati anche se presentano leggere differenze.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Valutazione della Similarit√†\n",
    "\n",
    "Una volta ottenute le coppie candidate tramite blocking e sorted neighbourhood, si procede a misurare la somiglianza tra i record.\n",
    "\n",
    "### Confronto del Nome dell‚ÄôAzienda con Algoritmi di Similarit√†\n",
    "- **Jaro-Winkler:**  \n",
    "  Questo algoritmo misura il grado di similarit√† tra due stringhe, gestendo variazioni, errori di battitura e trasposizioni.\n",
    "  \n",
    "  - **Funzionamento:**  \n",
    "    L'algoritmo calcola il numero di caratteri corrispondenti, valuta le trasposizioni e applica un bonus per prefissi comuni.\n",
    "  \n",
    "  - **Esempio pratico:**  \n",
    "    Confrontando \"MARTHA\" e \"MARHTA\", nonostante l'inversione di \"T\" e \"H\", il punteggio potrebbe essere alto (ad esempio, 0.94), indicando una forte somiglianza.\n",
    "\n",
    "### Confronti Esatti per Altri Attributi\n",
    "- **Descrizione:**  \n",
    "  Per attributi come settore e citt√†, si utilizza un confronto esatto: due record sono considerati corrispondenti solo se i valori sono identici.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Se due record indicano \"Tecnologia\" come settore e \"Roma\" come citt√†, il confronto esatto restituisce una corrispondenza perfetta (valore 1). Se anche uno solo dei due valori differisce, la corrispondenza fallisce (valore 0).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Definizione di Regole per il Matching\n",
    "\n",
    "Dopo aver calcolato i punteggi di similarit√† per ogni coppia, √® necessario definire regole per decidere se due record rappresentano la stessa entit√†.\n",
    "\n",
    "### Impostazione di Soglie di Similarit√†\n",
    "- **Descrizione:**  \n",
    "  Si stabiliscono delle soglie minime che il punteggio di similarit√† deve raggiungere affinch√© una coppia sia considerata un match.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Si pu√≤ decidere che un punteggio Jaro-Winkler superiore a 0.90 indichi che i nomi sono sufficientemente simili per suggerire un duplicato.\n",
    "\n",
    "### Combinazione di Condizioni su Pi√π Attributi\n",
    "- **Descrizione:**  \n",
    "  Le regole di matching combinano il punteggio del nome con confronti esatti per altri attributi (settore e citt√†).\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Una coppia di record viene considerata un match se:\n",
    "  - **Opzione 1:** Il punteggio del nome √® superiore a 0.90;  \n",
    "    **oppure**\n",
    "  - **Opzione 2:** Il punteggio del nome √® compreso tra 0.80 e 0.92 **e** sia il settore che la citt√† coincidono esattamente.\n",
    "  \n",
    "  Questo approccio riduce i falsi positivi, identificando come match solo le coppie con una forte corrispondenza in tutti i campi critici.\n",
    "\n",
    "### Bilanciamento tra Precisione e Recall\n",
    "- **Descrizione:**  \n",
    "  Le soglie e le regole vengono ottimizzate per bilanciare:\n",
    "  - **Precisione:** La percentuale di match corretti tra quelli identificati.\n",
    "  - **Recall:** La percentuale di duplicati reali individuati.\n",
    "  \n",
    "- **Esempio pratico:**  \n",
    "  Soglie troppo rigide possono portare a perdere duplicati reali (basso recall), mentre soglie troppo permissive possono includere troppi falsi positivi (bassa precisione). Un tuning accurato consente di raggiungere un equilibrio ottimale.\n",
    "\n",
    "---\n",
    "\n",
    "Questa spiegazione mostra come:\n",
    "- Le tecniche di **blocking** (per settore e citt√†) e **sorted neighbourhood** riducano il numero di confronti,\n",
    "- L'algoritmo **Jaro-Winkler** (insieme a confronti esatti) valuti la similarit√† tra record,\n",
    "- E le regole di matching combinino questi elementi per identificare duplicati in modo efficace, bilanciando precisione e recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_8332\\2525519434.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 9515230\n",
      "Dimensioni della similarity_matrix: (9515230, 3)\n",
      "Numero di coppie finali considerate 'match': 118429\n",
      "‚úÖ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di un blocking non troppo restrittivo\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 3) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "# 4) Calcolo della matrice di similarit√†\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# 5) Selezione coppie considerate match (esempio di regola)\n",
    "matches = similarity_matrix[\n",
    "    (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92) |\n",
    "    (similarity_matrix['name_sim'] > 0.9) & (similarity_matrix['industry_exact'] == 1) &\n",
    "     (similarity_matrix['city_exact'] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 6) Per avere i valori effettivi dei record, facciamo un \"join\" con df originale\n",
    "\n",
    "# a) Resettiamo l'indice (che √® una MultiIndex di coppie) per avere due colonne: 'level_0' e 'level_1'\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0':'id_left','level_1':'id_right'}, inplace=True)\n",
    "\n",
    "# Ora 'id_left' e 'id_right' sono gli indici del DataFrame df\n",
    "\n",
    "# b) Uniamo i valori delle colonne originali di 'df' per id_left\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "\n",
    "# c) Uniamo i valori delle colonne originali di 'df' per id_right\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Adesso, matches ha le colonne del record \"di sinistra\" (id_left) e del record \"di destra\" (id_right)\n",
    "# Es. company_name_left, industry_left, headquarters_city_left, company_name_right, industry_right, etc.\n",
    "# E contiene anche le colonne di similarit√†: name_sim, industry_exact, city_exact\n",
    "\n",
    "# INFINE, eliminiamo da matches, tutte le righe in cui i campi di company_name hanno esattamente la stessa identica stringa\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 7) Salvataggio in CSV con tutti i dati\n",
    "matches.to_csv(\"matched_companies_detailed.csv\", index=False)\n",
    "print(\"‚úÖ File 'matched_companies_detailed.csv' generato con i valori dei record affiancati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa contiene il file finale\n",
    "\n",
    "Dopo questo passaggio, il CSV `matched_companies_detailed.csv` avr√† le colonne:\n",
    "\n",
    "- `id_left` e `id_right`: gli indici Pandas dei due record matchati.\n",
    "- `name_sim`, `industry_exact`, `city_exact`: le metriche di somiglianza calcolate.\n",
    "- `company_name_left`, `industry_left`, `headquarters_city_left`: i valori presi dal DataFrame originale per il record \"di sinistra\".\n",
    "- `company_name_right`, `industry_right`, `headquarters_city_right`: idem per il record \"di destra\".\n",
    "\n",
    "In questo modo, visivamente puoi ispezionare se `company_name_left` e `company_name_right` sembrano davvero la stessa azienda, controllare se `industry_left` = `industry_right`, e cos√¨ via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convertire ground_truth.json in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversione completata! File 'ground_truth.csv' generato.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Leggiamo il JSON\n",
    "with open(\"data/ground_truth_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Creiamo il file CSV in scrittura\n",
    "with open(\"data/ground_truth.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # Scriviamo l'header\n",
    "    writer.writerow([\n",
    "        \"company_a\", \"industry_a\", \"country_a\", \"source_a\",\n",
    "        \"company_b\", \"industry_b\", \"country_b\", \"source_b\",\n",
    "        \"label\"\n",
    "    ])\n",
    "\n",
    "    # Per ogni record in data[\"ground_truth\"]\n",
    "    for record in data[\"ground_truth\"]:\n",
    "        pairs = record[\"pairs\"]\n",
    "        # Assumiamo che pairs contenga esattamente 2 elementi:\n",
    "        pair_a, pair_b = pairs[0], pairs[1]\n",
    "\n",
    "        # Estraiamo i valori per la prima azienda\n",
    "        company_a = pair_a.get(\"company-name\", \"\")\n",
    "        industry_a = pair_a.get(\"industry\", \"\")\n",
    "        country_a = pair_a.get(\"country\", \"\")\n",
    "        source_a = pair_a.get(\"source\", \"\")\n",
    "\n",
    "        # Estraiamo i valori per la seconda azienda\n",
    "        company_b = pair_b.get(\"company-name\", \"\")\n",
    "        industry_b = pair_b.get(\"industry\", \"\")\n",
    "        country_b = pair_b.get(\"country\", \"\")\n",
    "        source_b = pair_b.get(\"source\", \"\")\n",
    "\n",
    "        # Se il campo industry √® una lista, uniamo gli elementi in una stringa\n",
    "        if isinstance(industry_a, list):\n",
    "            industry_a = \"; \".join(industry_a)\n",
    "        if isinstance(industry_b, list):\n",
    "            industry_b = \"; \".join(industry_b)\n",
    "\n",
    "        # Convertiamo eventuali None in stringhe vuote\n",
    "        country_a = country_a or \"\"\n",
    "        country_b = country_b or \"\"\n",
    "        industry_a = industry_a or \"\"\n",
    "        industry_b = industry_b or \"\"\n",
    "\n",
    "        # Impostiamo la label: 1 se match √® true, 0 se false\n",
    "        label = 1 if record.get(\"match\", False) else 0\n",
    "\n",
    "        # Scriviamo la riga nel CSV\n",
    "        writer.writerow([\n",
    "            company_a, industry_a, country_a, source_a,\n",
    "            company_b, industry_b, country_b, source_b,\n",
    "            label\n",
    "        ])\n",
    "\n",
    "print(\"Conversione completata! File 'ground_truth.csv' generato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calcolo delle metriche di recision Recall e F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie in pairwise: 98726\n",
      "Numero di coppie in ground truth: 159\n",
      "Numero di coppie in ground truth con label a 1: 80\n",
      "Numero di coppie in intersezione: 145\n",
      "Numero di coppie nell'intersezione con label 1: 73\n",
      "Precision: 0.5034\n",
      "Recall: 0.9125\n",
      "F1-Score: 0.6489\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path dei file (aggiorna con i percorsi reali)\n",
    "pairwise_file = 'matched_companies_detailed.csv'\n",
    "groundtruth_file = 'data/ground_truth.csv'\n",
    "\n",
    "# Caricamento dei file\n",
    "pairwise = pd.read_csv(pairwise_file)\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# Funzione di supporto per normalizzare i nomi di societ√† (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# Funzione per ottenere una tupla ordinata, cos√¨ che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# Creiamo la colonna 'normalized_pair' in entrambi i dataset\n",
    "pairwise['normalized_pair'] = pairwise.apply(\n",
    "    lambda x: normalize_pair(x, 'company_name_left', 'company_name_right'), axis=1\n",
    ")\n",
    "groundtruth['normalized_pair'] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, 'company_a', 'company_b'), axis=1\n",
    ")\n",
    "\n",
    "# Convertiamo in insiemi per confronto\n",
    "pairwise_set = set(pairwise['normalized_pair'])\n",
    "groundtruth_set = set(groundtruth['normalized_pair'])\n",
    "\n",
    "# Intersezione tra le coppie del dataset pairwise e quelle della ground truth (tutte, indipendentemente dalla label)\n",
    "intersection = pairwise_set.intersection(groundtruth_set)\n",
    "\n",
    "# Filtriamo la ground truth per ottenere solo le coppie con label 1 (cio√® i match veri)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth['label'] == 1]['normalized_pair'])\n",
    "\n",
    "# Calcoliamo il numero di coppie dell'intersezione che hanno label 1\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# Calcolo delle metriche:\n",
    "# - Precisione: fra le coppie previste (cio√® quelle in intersezione), quanti sono corretti (label=1)\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "# - Recall: fra tutte le coppie corrette presenti in ground truth, quanti sono stati trovati\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output dei risultati\n",
    "print(f\"Numero di coppie in pairwise: {len(pairwise_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f'Numero di coppie in ground truth con label a 1: {len(groundtruth_true_set)}')\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie nell'intersezione con label 1: {tp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Blocking e Calcolo delle Metriche dei Risultati del Transformer\n",
    "\n",
    "Il seguente script √® utilizzato per calcolare le metriche di precisione, recall e F1-score dei risultati ottenuti dal modello Transformer per il matching delle entit√†. \n",
    "\n",
    "Questo script permette di valutare l'efficacia del modello Transformer nel riconoscere correttamente le coppie di entit√† duplicate, fornendo metriche chiave per l'analisi delle performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di record iniziali: 75793\n",
      "Numero di coppie candidate: 9515230\n",
      "Dimensioni della similarity_matrix: (9515230, 3)\n",
      "Numero di coppie finali considerate 'match': 118429\n",
      "‚úÖ Blocking e filtraggio completati! Coppie salvate in `blocked_pairs.tsv`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "#\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "#\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file, low_memory=False)\n",
    "\n",
    "# Seleziona alcune colonne di esempio\n",
    "df = df[['company_name', 'industry', 'headquarters_city']]\n",
    "\n",
    "# Rimuovi righe con company_name mancante\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 2) Creazione di un blocking ‚Äúnon troppo restrittivo‚Äù\n",
    "#\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Blocco per industry\n",
    "indexer.add(recordlinkage.index.Block('industry'))\n",
    "\n",
    "# Blocco per city\n",
    "indexer.add(recordlinkage.index.Block('headquarters_city'))\n",
    "\n",
    "# SortedNeighbourhood su company_name (finestra=5)\n",
    "indexer.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "\n",
    "# Creazione delle coppie candidate\n",
    "candidate_pairs = indexer.index(df)\n",
    "print(f\"Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 3) Definizione delle regole di confronto\n",
    "#\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Similarit√† Jaro-Winkler sul nome\n",
    "compare.string('company_name', 'company_name', method='jarowinkler', label='name_sim')\n",
    "\n",
    "# Check esatto su industry\n",
    "compare.exact('industry', 'industry', label='industry_exact')\n",
    "\n",
    "# Check esatto su city\n",
    "compare.exact('headquarters_city', 'headquarters_city', label='city_exact')\n",
    "\n",
    "\n",
    "#\n",
    "# 4) Calcolo della matrice di similarit√†\n",
    "#\n",
    "similarity_matrix = compare.compute(candidate_pairs, df)\n",
    "print(f\"Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 5) Selezione delle coppie ‚Äúmatch‚Äù (stessa logica del vecchio script)\n",
    "#\n",
    "# Regola:\n",
    "#  - name_sim > 0.80 e < 0.92, OPPURE\n",
    "#  - name_sim > 0.9 e industry_exact == 1 e city_exact == 1\n",
    "#\n",
    "matches = similarity_matrix[\n",
    "    (\n",
    "        (similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92)\n",
    "    )\n",
    "    |\n",
    "    (\n",
    "        (similarity_matrix['name_sim'] > 0.9)\n",
    "        & (similarity_matrix['industry_exact'] == 1)\n",
    "        & (similarity_matrix['city_exact'] == 1)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "\n",
    "#\n",
    "# 6) Convertiamo queste coppie in formato TSV per il Transformer\n",
    "#\n",
    "\n",
    "# a) Resettiamo l'indice (MultiIndex -> 'level_0' e 'level_1')\n",
    "matches = matches.reset_index()\n",
    "\n",
    "# b) Creiamo le colonne da esportare\n",
    "matches['sentence1'] = df.loc[matches['level_0'], 'company_name'].values\n",
    "matches['sentence2'] = df.loc[matches['level_1'], 'company_name'].values\n",
    "matches['label'] = \"?\"  # non hai etichette, lasciamo \"?\". Cambia se serve.\n",
    "\n",
    "# Opzionalmente, se vuoi evitare duplicati con company_name identici\n",
    "# matches = matches[matches['sentence1'] != matches['sentence2']]\n",
    "\n",
    "#\n",
    "# 7) Salvataggio in TSV\n",
    "#\n",
    "matches[[\"level_0\", \"sentence1\", \"sentence2\", \"label\"]].to_csv(\n",
    "    \"entity-matching-transformer/blocked_pairs.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Blocking e filtraggio completati! Coppie salvate in `blocked_pairs.tsv`.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conteggio intersezione blocking con gt\n",
    "\n",
    "Questo script serve per contare le coppie di intersezione tra i risultati del blocking e la ground truth (GT). Utilizza tecniche di normalizzazione dei nomi delle aziende per garantire che le coppie siano confrontate in modo coerente, indipendentemente dall'ordine o dalle variazioni minori nei nomi. L'intersezione risultante fornisce un'indicazione di quante coppie identificate nel blocking sono effettivamente presenti nella ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BLOCKED] Numero di coppie nel file di blocking: 118429\n",
      "[GT] Numero di coppie totali nella ground truth: 159\n",
      "[BLOCKED] Numero di coppie distinte (normalizzate) nel blocking: 98110\n",
      "[GT] Numero di coppie distinte (normalizzate) nella ground truth: 159\n",
      "[INFO] Numero di coppie del blocking che sono nella GT: 145\n",
      "[INFO] Percentuale di coppie di blocking trovate nella GT: 0.15%\n",
      "Esempi di coppie trovate in BOTH (blocking e GT):\n",
      "[('shenzhen minde electronics technology', 'shenzhen mindray biomedical electronics'), ('pzu', 'pzu sa'), ('andhra bank', 'andhra paper'), ('51job', '51job inc'), ('nomura co ltd', 'nomura holdings')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# (1) Lettura delle coppie risultanti dal blocking\n",
    "# ------------------------------------------------\n",
    "df_blocked = pd.read_csv(\n",
    "    \"entity-matching-transformer/blocked_pairs.tsv\", \n",
    "    sep=\"\\t\"\n",
    ")\n",
    "# Supponendo che il tuo TSV abbia queste colonne: [\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    "# Verifica che le colonne coincidano con quelle che hai salvato!\n",
    "\n",
    "print(f\"[BLOCKED] Numero di coppie nel file di blocking: {len(df_blocked)}\")\n",
    "\n",
    "# (2) Lettura della ground truth\n",
    "# ------------------------------------------------\n",
    "df_gt = pd.read_csv(\"data/ground_truth.csv\")\n",
    "\n",
    "print(f\"[GT] Numero di coppie totali nella ground truth: {len(df_gt)}\")\n",
    "\n",
    "\n",
    "# (3) Funzione di normalizzazione dei nomi (opzionale)\n",
    "# ------------------------------------------------\n",
    "def normalize_company_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Esempio semplice di normalizzazione:\n",
    "    - converti in minuscolo\n",
    "    - rimuovi punteggiatura\n",
    "    - fai strip di spazi iniziali/finali\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"  # o gestisci diversamente i NaN\n",
    "    name = name.lower().strip()\n",
    "    # Rimuove caratteri non alfanumerici (tranne spazi)\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    # Rimuove eventuali doppi spazi\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "# (4) Creazione di set di coppie \"normalizzate\" per il blocking\n",
    "# -------------------------------------------------------------\n",
    "# Se vuoi considerare la coppia come NON ordinata (A,B) == (B,A), ordina i nomi:\n",
    "blocked_pairs_set = set()\n",
    "\n",
    "for idx, row in df_blocked.iterrows():\n",
    "    # Normalizza i nomi\n",
    "    c1 = normalize_company_name(row[\"sentence1\"])\n",
    "    c2 = normalize_company_name(row[\"sentence2\"])\n",
    "    # Ordina la tuple, cosi \"A-B\" e \"B-A\" finiscono uguali\n",
    "    pair = tuple(sorted([c1, c2]))\n",
    "    blocked_pairs_set.add(pair)\n",
    "\n",
    "print(f\"[BLOCKED] Numero di coppie distinte (normalizzate) nel blocking: {len(blocked_pairs_set)}\")\n",
    "\n",
    "\n",
    "# (5) Creazione di set di coppie \"normalizzate\" per la ground truth\n",
    "# -----------------------------------------------------------------\n",
    "gt_pairs_set = set()\n",
    "\n",
    "for idx, row in df_gt.iterrows():\n",
    "    # Puoi considerare solo company_a e company_b (se sono i campi che t'interessano per l'allineamento)\n",
    "    c_a = normalize_company_name(row[\"company_a\"])\n",
    "    c_b = normalize_company_name(row[\"company_b\"])\n",
    "    # Anche qui, se vuoi l'ordine non rilevante, fai sorted\n",
    "    pair = tuple(sorted([c_a, c_b]))\n",
    "    gt_pairs_set.add(pair)\n",
    "\n",
    "print(f\"[GT] Numero di coppie distinte (normalizzate) nella ground truth: {len(gt_pairs_set)}\")\n",
    "\n",
    "\n",
    "# (6) Intersezione tra i due insiemi\n",
    "# ----------------------------------\n",
    "intersection_pairs = blocked_pairs_set.intersection(gt_pairs_set)\n",
    "\n",
    "print(f\"[INFO] Numero di coppie del blocking che sono nella GT: {len(intersection_pairs)}\")\n",
    "\n",
    "# Eventualmente, puoi calcolare anche la quota in percentuale\n",
    "perc = (len(intersection_pairs) / len(blocked_pairs_set)) * 100 if len(blocked_pairs_set) else 0\n",
    "print(f\"[INFO] Percentuale di coppie di blocking trovate nella GT: {perc:.2f}%\")\n",
    "\n",
    "# (7) Se vuoi, puoi anche estrarre le righe corrispondenti all‚Äôintersezione\n",
    "# in modo da analizzarle:\n",
    "intersection_list = list(intersection_pairs)\n",
    "\n",
    "# *Attenzione*: se vuoi fare un join tabellare pi√π classico, \n",
    "# dovresti creare un DF con \"c1_norm\", \"c2_norm\" e poi fare merge con \n",
    "# un DF analogo per la GT.\n",
    "\n",
    "# Per semplicit√†, stampiamo solo qualche esempio di coppie in comune\n",
    "print(\"Esempi di coppie trovate in BOTH (blocking e GT):\")\n",
    "print(intersection_list[:5])  # prime 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie predette come match dal modello: 1484\n",
      "Numero di coppie in ground truth: 159\n",
      "Numero di coppie in ground truth con label 1: 80\n",
      "Numero di coppie in intersezione: 14\n",
      "Numero di coppie corrette (True Positives): 11\n",
      "üìå Precision: 0.7857\n",
      "üìå Recall: 0.1375\n",
      "üìå F1-Score: 0.2340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# üìÇ Percorsi dei file (aggiorna con i percorsi reali)\n",
    "model_output_file = \"entity-matching-transformer/predicted_matches.tsv\"  # File generato dal modello\n",
    "groundtruth_file = \"data/ground_truth.csv\"  # Ground truth\n",
    "\n",
    "# üì• Caricamento dei file\n",
    "model_results = pd.read_csv(model_output_file, sep=\"\\t\")\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# üîç Normalizzazione dei nomi di societ√† (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# üìå Funzione per ottenere una tupla ordinata, cos√¨ che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# üìä Filtriamo solo le coppie che il modello ha predetto come match (label 1)\n",
    "model_results = model_results[model_results[\"label\"] == 1]\n",
    "\n",
    "# üõ† Creiamo la colonna 'normalized_pair' nei dataset\n",
    "model_results[\"normalized_pair\"] = model_results.apply(\n",
    "    lambda x: normalize_pair(x, \"sentence1\", \"sentence2\"), axis=1\n",
    ")\n",
    "groundtruth[\"normalized_pair\"] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, \"company_a\", \"company_b\"), axis=1\n",
    ")\n",
    "\n",
    "# üîÄ Convertiamo in insiemi per confronto\n",
    "model_set = set(model_results[\"normalized_pair\"])\n",
    "groundtruth_set = set(groundtruth[\"normalized_pair\"])\n",
    "\n",
    "# üîó Intersezione tra le coppie predette e quelle nella ground truth\n",
    "intersection = model_set.intersection(groundtruth_set)\n",
    "\n",
    "# üéØ Filtriamo la ground truth per ottenere solo i veri match (label = 1)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth[\"label\"] == 1][\"normalized_pair\"])\n",
    "\n",
    "# ‚úÖ Calcoliamo il numero di True Positives (coppie predette che sono davvero match)\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# üìä Calcolo delle metriche:\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# üì¢ Output dei risultati\n",
    "print(f\"Numero di coppie predette come match dal modello: {len(model_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f\"Numero di coppie in ground truth con label 1: {len(groundtruth_true_set)}\")\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie corrette (True Positives): {tp}\")\n",
    "print(f\"üìå Precision: {precision:.4f}\")\n",
    "print(f\"üìå Recall: {recall:.4f}\")\n",
    "print(f\"üìå F1-Score: {f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
