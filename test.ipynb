{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking completato e salvato in JSON!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "import jellyfish\n",
    "import json\n",
    "\n",
    "# Caricamento dei dati\n",
    "df = pd.read_csv(\"main_outputs/final_mediated_schema.csv\", low_memory=False)\n",
    "\n",
    "# Assicurati che il nome dell'azienda sia stringa\n",
    "df[\"company_name\"] = df[\"company_name\"].astype(str)\n",
    "\n",
    "# Creazione di un identificativo unico per ogni record\n",
    "df[\"index\"] = df.index\n",
    "\n",
    "# Strategie di Blocking\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Blocking 1: Basato sulle prime 3 lettere del nome dell'azienda\n",
    "df[\"prefix_3\"] = df[\"company_name\"].str[:3]\n",
    "indexer.block(left_on=\"prefix_3\")\n",
    "\n",
    "# Blocking 2: Basato su Soundex (usando jellyfish)\n",
    "df[\"soundex\"] = df[\"company_name\"].apply(lambda x: jellyfish.soundex(x))\n",
    "indexer.block(left_on=\"soundex\")\n",
    "\n",
    "# Creazione dei candidati per il matching\n",
    "candidate_links_1 = indexer.index(df)\n",
    "candidate_links_2 = indexer.index(df)\n",
    "\n",
    "# Funzione per trasformare gli ID in valori leggibili\n",
    "def convert_pairs_to_json(candidate_links, filename):\n",
    "    pairs_list = []\n",
    "    \n",
    "    for id1, id2 in candidate_links:\n",
    "        row1 = df.loc[id1]\n",
    "        row2 = df.loc[id2]\n",
    "        \n",
    "        pairs_list.append({\n",
    "            \"company_1\": row1[\"company_name\"],\n",
    "            \"company_2\": row2[\"company_name\"],\n",
    "            \"source_1\": row1[\"_source_table\"] if \"_source_table\" in df.columns else None,\n",
    "            \"source_2\": row2[\"_source_table\"] if \"_source_table\" in df.columns else None\n",
    "        })\n",
    "    \n",
    "    # Salva in JSON\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(pairs_list, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Salvare i risultati del blocking come JSON leggibile\n",
    "convert_pairs_to_json(candidate_links_1, \"blocking_output_1.json\")\n",
    "convert_pairs_to_json(candidate_links_2, \"blocking_output_2.json\")\n",
    "\n",
    "print(\"Blocking completato e salvato in JSON!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0003\n",
      "Recall: 1.0000\n",
      "F1-score: 0.0005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Funzione per calcolare la similarità tra stringhe\n",
    "def similar(a, b) -> float:\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Caricamento della ground truth\n",
    "with open(\"data/ground_truth.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ground_truth = json.load(f)[\"ground_truth\"]\n",
    "\n",
    "# Convertiamo la ground truth in un set di tuple per confrontarle più facilmente\n",
    "gt_pairs = set((list(gt.keys())[0], list(gt.keys())[1]) for gt in ground_truth)\n",
    "\n",
    "# Caricamento delle coppie generate dal blocking\n",
    "with open(\"blocking_output_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    candidate_pairs = json.load(f)\n",
    "\n",
    "# Caricamento del dataset principale\n",
    "df = pd.read_csv(\"main_outputs/final_mediated_schema.csv\", low_memory=False)\n",
    "\n",
    "# Creiamo un DataFrame per le coppie candidate\n",
    "pairs_df = pd.DataFrame(candidate_pairs)\n",
    "\n",
    "# Creiamo un indice numerico per unire i dati più facilmente\n",
    "df = df.reset_index()\n",
    "\n",
    "# Creiamo un dizionario per mappare i nomi aziendali agli ID del DataFrame\n",
    "company_to_index = df.set_index(\"company_name\")[\"index\"].to_dict()\n",
    "\n",
    "# Convertiamo le coppie candidate in un MultiIndex di ID\n",
    "pairs_idx = [\n",
    "    (company_to_index.get(row[\"company_1\"]), company_to_index.get(row[\"company_2\"]))\n",
    "    for _, row in pairs_df.iterrows()\n",
    "    if row[\"company_1\"] in company_to_index and row[\"company_2\"] in company_to_index\n",
    "]\n",
    "\n",
    "# Creiamo un MultiIndex valido\n",
    "pairs_index = pd.MultiIndex.from_tuples(pairs_idx, names=[\"id1\", \"id2\"])\n",
    "\n",
    "# Creazione del confronto tra le coppie di dati\n",
    "compare = recordlinkage.Compare()\n",
    "compare.string(\"company_name\", \"company_name\", method=\"jarowinkler\", threshold=0.85, label=\"name_similarity\")\n",
    "\n",
    "# Ora passiamo correttamente il MultiIndex come primo argomento\n",
    "df_indexed = df.set_index(\"index\")  # Assicuriamoci che il DataFrame sia indicizzato correttamente\n",
    "features = compare.compute(pairs_index, df_indexed)  # Ora funziona\n",
    "\n",
    "# Selezioniamo le coppie che superano la soglia di similarità\n",
    "threshold = 0.95\n",
    "matched_pairs = set(\n",
    "    (df.loc[id1, \"company_name\"], df.loc[id2, \"company_name\"])\n",
    "    for (id1, id2), row in features.iterrows()\n",
    "    if row[\"name_similarity\"] > threshold\n",
    ")\n",
    "\n",
    "# Creazione delle liste per le metriche\n",
    "y_true = [1 if pair in gt_pairs else 0 for pair in matched_pairs]\n",
    "y_pred = [1] * len(matched_pairs)  # Tutte le coppie trovate sono considerate come predizioni positive\n",
    "\n",
    "# Calcolo delle metriche\n",
    "precision = precision_score(y_true, y_pred) if len(set(y_true)) > 1 else 0\n",
    "recall = recall_score(y_true, y_pred) if len(set(y_true)) > 1 else 0\n",
    "f1 = f1_score(y_true, y_pred) if len(set(y_true)) > 1 else 0\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
