{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca-\\AppData\\Local\\Temp\\ipykernel_24856\\1170323690.py:6: DtypeWarning: Columns (2,5,6,7,9,14,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(schema_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Script con blocking combinato] Numero di record iniziali: 75793\n",
      "[Script con blocking combinato] Numero di coppie candidate: 46228525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# 1) Caricamento e pre-elaborazione dati\n",
    "schema_file = \"main_outputs/final_mediated_schema.csv\"\n",
    "df = pd.read_csv(schema_file)\n",
    "\n",
    "# Seleziona alcune colonne di interesse\n",
    "df = df[['company_name', 'industry', 'headquarters_country', 'headquarters_city', 'year_founded']]\n",
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "\n",
    "print(f\"[Script con blocking combinato] Numero di record iniziali: {len(df)}\")\n",
    "\n",
    "# 2) Creazione di due insiemi di coppie candidate\n",
    "#    A) Blocco su headquarters_country + SortedNeighbourhood su company_name\n",
    "indexer_1 = recordlinkage.Index()\n",
    "indexer_1.add(recordlinkage.index.Block('headquarters_country'))\n",
    "indexer_1.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "candidate_pairs_country = indexer_1.index(df)\n",
    "\n",
    "#    B) Blocco su headquarters_city + SortedNeighbourhood su company_name\n",
    "indexer_2 = recordlinkage.Index()\n",
    "indexer_2.add(recordlinkage.index.Block('headquarters_city'))\n",
    "indexer_2.add(recordlinkage.index.SortedNeighbourhood('company_name', window=5))\n",
    "candidate_pairs_city = indexer_2.index(df)\n",
    "\n",
    "# 3) Creazione delle coppie finali come UNIONE dei due insiemi\n",
    "candidates_country_set = set(candidate_pairs_country)\n",
    "candidates_city_set = set(candidate_pairs_city)\n",
    "candidate_pairs = candidates_country_set.union(candidates_city_set)\n",
    "\n",
    "print(f\"[Script con blocking combinato] Numero di coppie candidate: {len(candidate_pairs)}\")\n",
    "\n",
    "# 4) Definizione delle regole di confronto\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Similarità sul company_name (jarowinkler)\n",
    "compare.string('company_name',\n",
    "               'company_name',\n",
    "               method='jarowinkler',\n",
    "               label='name_sim')\n",
    "\n",
    "# Similarità su industry (jarowinkler)\n",
    "compare.string('industry',\n",
    "               'industry',\n",
    "               method='jarowinkler',\n",
    "               label='industry_sim')\n",
    "\n",
    "# Similarità su headquarters_country (jarowinkler)\n",
    "compare.string('headquarters_country',\n",
    "               'headquarters_country',\n",
    "               method='jarowinkler',\n",
    "               label='country_sim')\n",
    "\n",
    "# Se desideri, puoi anche aggiungere la similarità su 'headquarters_city':\n",
    "# compare.string('headquarters_city', 'headquarters_city', method='jarowinkler', label='city_sim')\n",
    "\n",
    "# 5) Calcolo della matrice di similarità\n",
    "#    (convertiamo il set di coppie in una lista, così `compare.compute()` non dà errori)\n",
    "# ...\n",
    "# 5) Calcolo della matrice di similarità\n",
    "#    Convertiamo l'insieme di tuple in una lista e poi in un MultiIndex\n",
    "\n",
    "candidate_pairs_list = list(candidate_pairs)\n",
    "\n",
    "# Crea un MultiIndex a partire dalla lista di tuple\n",
    "candidate_pairs_mi = pd.MultiIndex.from_tuples(candidate_pairs_list, names=['level_0', 'level_1'])\n",
    "\n",
    "similarity_matrix = compare.compute(candidate_pairs_mi, df)\n",
    "print(f\"[Script con blocking combinato] Dimensioni della similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "\n",
    "# 6) Definizione delle regole di matching (esempio)\n",
    "matches = similarity_matrix[\n",
    "    # (1) Nome simile 0.80 - 0.92\n",
    "    ((similarity_matrix['name_sim'] > 0.80) & (similarity_matrix['name_sim'] < 0.92))\n",
    "    |\n",
    "    # (2) Nome > 0.9 e industry_sim > 0.5 e country_sim > 0.5\n",
    "    ((similarity_matrix['name_sim'] > 0.9) & \n",
    "     (similarity_matrix['industry_sim'] > 0.5) &\n",
    "     (similarity_matrix['country_sim'] > 0.5))\n",
    "]\n",
    "\n",
    "print(f\"[Script con blocking combinato] Numero di coppie finali considerate 'match': {len(matches)}\")\n",
    "\n",
    "# 7) Recupero dei record (join con df originale)\n",
    "matches = matches.reset_index()\n",
    "matches.rename(columns={'level_0': 'id_left', 'level_1': 'id_right'}, inplace=True)\n",
    "matches = matches.merge(df, left_on='id_left', right_index=True, how='left', suffixes=('', '_left'))\n",
    "matches = matches.merge(df, left_on='id_right', right_index=True, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Eliminiamo le righe in cui i campi company_name sono identici (stesso record)\n",
    "matches = matches[matches['company_name_left'] != matches['company_name_right']]\n",
    "\n",
    "# 8) Salvataggio in CSV\n",
    "output_file = \"matched_companies_detailed_blocking_2.csv\"\n",
    "matches.to_csv(output_file, index=False)\n",
    "print(f\"[Script con blocking combinato] ✅ File '{output_file}' generato!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di coppie in pairwise: 82726\n",
      "Numero di coppie in ground truth: 182\n",
      "Numero di coppie in ground truth con label a 1: 82\n",
      "Numero di coppie in intersezione: 167\n",
      "Numero di coppie nell'intersezione con label 1: 73\n",
      "Precision: 0.4371\n",
      "Recall: 0.8902\n",
      "F1-Score: 0.5863\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path dei file (aggiorna con i percorsi reali)\n",
    "pairwise_file = 'matched_companies_detailed_blocking_2.csv'\n",
    "groundtruth_file = 'data/ground_truth.csv'\n",
    "\n",
    "# Caricamento dei file\n",
    "pairwise = pd.read_csv(pairwise_file)\n",
    "groundtruth = pd.read_csv(groundtruth_file)\n",
    "\n",
    "# Funzione di supporto per normalizzare i nomi di società (rimuove spazi e usa lowercase)\n",
    "def normalize_name(name):\n",
    "    return name.strip().lower() if isinstance(name, str) else str(name).lower()\n",
    "\n",
    "# Funzione per ottenere una tupla ordinata, così che l'ordine non conti\n",
    "def normalize_pair(row, col1, col2):\n",
    "    left = normalize_name(row[col1])\n",
    "    right = normalize_name(row[col2])\n",
    "    return tuple(sorted([left, right]))\n",
    "\n",
    "# Creiamo la colonna 'normalized_pair' in entrambi i dataset\n",
    "pairwise['normalized_pair'] = pairwise.apply(\n",
    "    lambda x: normalize_pair(x, 'company_name_left', 'company_name_right'), axis=1\n",
    ")\n",
    "groundtruth['normalized_pair'] = groundtruth.apply(\n",
    "    lambda x: normalize_pair(x, 'company_a', 'company_b'), axis=1\n",
    ")\n",
    "\n",
    "# Convertiamo in insiemi per confronto\n",
    "pairwise_set = set(pairwise['normalized_pair'])\n",
    "groundtruth_set = set(groundtruth['normalized_pair'])\n",
    "\n",
    "# Intersezione tra le coppie del dataset pairwise e quelle della ground truth (tutte, indipendentemente dalla label)\n",
    "intersection = pairwise_set.intersection(groundtruth_set)\n",
    "\n",
    "# Filtriamo la ground truth per ottenere solo le coppie con label 1 (cioè i match veri)\n",
    "groundtruth_true_set = set(groundtruth[groundtruth['label'] == 1]['normalized_pair'])\n",
    "\n",
    "# Calcoliamo il numero di coppie dell'intersezione che hanno label 1\n",
    "tp = len(intersection.intersection(groundtruth_true_set))\n",
    "\n",
    "# Calcolo delle metriche:\n",
    "# - Precisione: fra le coppie previste (cioè quelle in intersezione), quanti sono corretti (label=1)\n",
    "precision = tp / len(intersection) if len(intersection) else 0\n",
    "# - Recall: fra tutte le coppie corrette presenti in ground truth, quanti sono stati trovati\n",
    "recall = tp / len(groundtruth_true_set) if len(groundtruth_true_set) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output dei risultati\n",
    "print(f\"Numero di coppie in pairwise: {len(pairwise_set)}\")\n",
    "print(f\"Numero di coppie in ground truth: {len(groundtruth_set)}\")\n",
    "print(f'Numero di coppie in ground truth con label a 1: {len(groundtruth_true_set)}')\n",
    "print(f\"Numero di coppie in intersezione: {len(intersection)}\")\n",
    "print(f\"Numero di coppie nell'intersezione con label 1: {tp}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
